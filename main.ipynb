{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções customizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation and numbers from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A string\n",
    "\n",
    "    Returns:\n",
    "        str: string without punctuation and numbers\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "def remove_multiple_blank_spaces(text):\n",
    "    \"\"\"Remove multiple blank spaces from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A string\n",
    "\n",
    "    Returns:\n",
    "        str: string with only one space between words\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "1         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "2         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "3         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/10/1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"Input/archive.zip\", low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "text              765\n",
       "date                0\n",
       "category            0\n",
       "subcategory    137418\n",
       "link                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count empty values by columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poder</th>\n",
       "      <td>22022</td>\n",
       "      <td>22022</td>\n",
       "      <td>22022</td>\n",
       "      <td>939</td>\n",
       "      <td>22022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colunas</th>\n",
       "      <td>21622</td>\n",
       "      <td>21619</td>\n",
       "      <td>21622</td>\n",
       "      <td>21622</td>\n",
       "      <td>21622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercado</th>\n",
       "      <td>20970</td>\n",
       "      <td>20970</td>\n",
       "      <td>20970</td>\n",
       "      <td>0</td>\n",
       "      <td>20970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esporte</th>\n",
       "      <td>19730</td>\n",
       "      <td>19730</td>\n",
       "      <td>19730</td>\n",
       "      <td>2859</td>\n",
       "      <td>19730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mundo</th>\n",
       "      <td>17130</td>\n",
       "      <td>17130</td>\n",
       "      <td>17130</td>\n",
       "      <td>0</td>\n",
       "      <td>17130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cotidiano</th>\n",
       "      <td>16967</td>\n",
       "      <td>16967</td>\n",
       "      <td>16967</td>\n",
       "      <td>35</td>\n",
       "      <td>16967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrada</th>\n",
       "      <td>16345</td>\n",
       "      <td>15617</td>\n",
       "      <td>16345</td>\n",
       "      <td>0</td>\n",
       "      <td>16345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opiniao</th>\n",
       "      <td>4525</td>\n",
       "      <td>4525</td>\n",
       "      <td>4525</td>\n",
       "      <td>0</td>\n",
       "      <td>4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paineldoleitor</th>\n",
       "      <td>4011</td>\n",
       "      <td>4011</td>\n",
       "      <td>4011</td>\n",
       "      <td>260</td>\n",
       "      <td>4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saopaulo</th>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>471</td>\n",
       "      <td>3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tec</th>\n",
       "      <td>2260</td>\n",
       "      <td>2260</td>\n",
       "      <td>2260</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>2142</td>\n",
       "      <td>2123</td>\n",
       "      <td>2142</td>\n",
       "      <td>2142</td>\n",
       "      <td>2142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educacao</th>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "      <td>0</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turismo</th>\n",
       "      <td>1903</td>\n",
       "      <td>1903</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrissima</th>\n",
       "      <td>1411</td>\n",
       "      <td>1409</td>\n",
       "      <td>1411</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciencia</th>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>0</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equilibrioesaude</th>\n",
       "      <td>1312</td>\n",
       "      <td>1312</td>\n",
       "      <td>1312</td>\n",
       "      <td>0</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sobretudo</th>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folhinha</th>\n",
       "      <td>876</td>\n",
       "      <td>875</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empreendedorsocial</th>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>150</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comida</th>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asmais</th>\n",
       "      <td>548</td>\n",
       "      <td>547</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambiente</th>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seminariosfolha</th>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serafina</th>\n",
       "      <td>334</td>\n",
       "      <td>331</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o-melhor-de-sao-paulo</th>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>71</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vice</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guia-de-livros-discos-filmes</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topofmind</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banco-de-dados</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>especial</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infograficos</th>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cenarios-2017</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfi</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guia-de-livros-filmes-discos</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multimidia</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treinamento</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treinamentocienciaesaude</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mulher</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euronews</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ombudsman</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contas-de-casa</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bichos</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musica</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title   text   date  subcategory   link\n",
       "category                                                             \n",
       "poder                         22022  22022  22022          939  22022\n",
       "colunas                       21622  21619  21622        21622  21622\n",
       "mercado                       20970  20970  20970            0  20970\n",
       "esporte                       19730  19730  19730         2859  19730\n",
       "mundo                         17130  17130  17130            0  17130\n",
       "cotidiano                     16967  16967  16967           35  16967\n",
       "ilustrada                     16345  15617  16345            0  16345\n",
       "opiniao                        4525   4525   4525            0   4525\n",
       "paineldoleitor                 4011   4011   4011          260   4011\n",
       "saopaulo                       3955   3955   3955          471   3955\n",
       "tec                            2260   2260   2260            0   2260\n",
       "tv                             2142   2123   2142         2142   2142\n",
       "educacao                       2118   2118   2118            0   2118\n",
       "turismo                        1903   1903   1903            0   1903\n",
       "ilustrissima                   1411   1409   1411            0   1411\n",
       "ciencia                        1335   1335   1335            0   1335\n",
       "equilibrioesaude               1312   1312   1312            0   1312\n",
       "sobretudo                      1057   1057   1057         1057   1057\n",
       "bbc                             980    980    980            0    980\n",
       "folhinha                        876    875    876            0    876\n",
       "empreendedorsocial              841    841    841          150    841\n",
       "comida                          828    828    828            0    828\n",
       "asmais                          548    547    548            0    548\n",
       "ambiente                        491    491    491            0    491\n",
       "seminariosfolha                 379    379    379            0    379\n",
       "serafina                        334    331    334            0    334\n",
       "o-melhor-de-sao-paulo           189    189    189           71    189\n",
       "vice                            146    146    146            0    146\n",
       "guia-de-livros-discos-filmes    143    143    143            0    143\n",
       "topofmind                        86     86     86            0     86\n",
       "banco-de-dados                   64     64     64            0     64\n",
       "dw                               48     48     48            0     48\n",
       "especial                         43     43     43            0     43\n",
       "infograficos                     43     40     43            0     43\n",
       "cenarios-2017                    43     43     43            0     43\n",
       "rfi                              29     29     29            0     29\n",
       "guia-de-livros-filmes-discos     28     28     28            0     28\n",
       "multimidia                       27     27     27           27     27\n",
       "treinamento                      21     21     21            0     21\n",
       "treinamentocienciaesaude         18     18     18            0     18\n",
       "mulher                           16     16     16            0     16\n",
       "euronews                          8      8      8            0      8\n",
       "ombudsman                         3      3      3            0      3\n",
       "contas-de-casa                    2      0      2            2      2\n",
       "2016                              1      0      1            0      1\n",
       "bichos                            1      1      1            0      1\n",
       "musica                            1      0      1            0      1\n",
       "2015                              1      0      1            0      1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count items by category\n",
    "data.groupby(\"category\").count().sort_values(by=\"title\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 167053 entries, 0 to 166970\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        167053 non-null  object\n",
      " 1   text         166288 non-null  object\n",
      " 2   date         167053 non-null  object\n",
      " 3   category     167053 non-null  object\n",
      " 4   subcategory  29635 non-null   object\n",
      " 5   link         167053 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 8.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# To avoid unbalanced data, we will remove the categories with less than 1500 items\n",
    "categories_mask = data[\"category\"].value_counts() > 1500\n",
    "categories_mask = categories_mask[categories_mask.values].index\n",
    "# Filter data\n",
    "mask = data[\"category\"].isin(categories_mask)\n",
    "data_filtered = data[mask]\n",
    "temp_df = data.loc[~mask]\n",
    "temp_df[\"category\"] = \"outros\"\n",
    "\n",
    "data_filtered = pd.concat([data_filtered, temp_df])\n",
    "data_filtered.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "poder             22022\n",
       "colunas           21622\n",
       "mercado           20970\n",
       "esporte           19730\n",
       "mundo             17130\n",
       "cotidiano         16967\n",
       "ilustrada         16345\n",
       "outros            11353\n",
       "opiniao            4525\n",
       "paineldoleitor     4011\n",
       "saopaulo           3955\n",
       "tec                2260\n",
       "tv                 2142\n",
       "educacao           2118\n",
       "turismo            1903\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 333\n",
    "data_balanced = data_filtered.copy()#.groupby('category').apply(lambda x: x.sample(1500, random_state=seed))\n",
    "\n",
    "# Store the unused data for future use\n",
    "# balanced_index = set(data_balanced.unstack(level=0).index)\n",
    "# balanced_categories = data_balanced.category.unique()\n",
    "# mask = ~(data_filtered.index.isin(balanced_index)) & (data_filtered.category.isin(balanced_categories))\n",
    "# data_unbalanced = data_filtered[mask].reset_index(drop=True)\n",
    "\n",
    "# Balanced data\n",
    "data_balanced.reset_index(drop=True, inplace=True)\n",
    "data_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>lula diz que esta lascado mas que ainda tem fo...</td>\n",
       "      <td>poder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>decidi ser escrava das mulheres que sofrem diz...</td>\n",
       "      <td>ilustrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>tres reportagens da folha ganham premio petrob...</td>\n",
       "      <td>poder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>filme star wars os ultimos jedi ganha trailer ...</td>\n",
       "      <td>ilustrada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>cbss inicia acordos com fintechs e quer do cre...</td>\n",
       "      <td>mercado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                           norm_text   category  \n",
       "0  lula diz que esta lascado mas que ainda tem fo...      poder  \n",
       "1  decidi ser escrava das mulheres que sofrem diz...  ilustrada  \n",
       "2  tres reportagens da folha ganham premio petrob...      poder  \n",
       "3  filme star wars os ultimos jedi ganha trailer ...  ilustrada  \n",
       "4  cbss inicia acordos com fintechs e quer do cre...    mercado  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining text and title\n",
    "df_balanced = data_balanced[[\"title\", \"text\", \"category\"]].copy()\n",
    "df_balanced[\"full_text\"] = df_balanced[\"title\"] + \" \" + df_balanced[\"text\"]\n",
    "# Text cleaning\n",
    "df_balanced[\"norm_text\"] = df_balanced.full_text.apply(lambda x: remove_multiple_blank_spaces(\n",
    "                                                remove_punctuation(\n",
    "                                                    unidecode(str(x).lower())\n",
    "                                                )\n",
    "                                            ).strip())\n",
    "df_balanced = df_balanced[[\"full_text\", \"norm_text\", \"category\"]]\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change category to numeric\n",
    "df_balanced[\"category\"] = df_balanced.category.astype(\"category\")\n",
    "category_map = {key: value for key, value in zip(df_balanced.category, df_balanced.category.cat.codes)}\n",
    "df_balanced.category = df_balanced.category.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133642, 3), (16705, 3), (16706, 3))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_balanced, test_size=0.2, random_state=314, stratify=df_balanced.category)\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.5, random_state=314, stratify=df_test.category)\n",
    "\n",
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words and vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 3),\n",
       "                stop_words=[&#x27;inclusive&#x27;, &#x27;a&#x27;, &#x27;tem&#x27;, &#x27;delas&#x27;, &#x27;pelos&#x27;, &#x27;elas&#x27;,\n",
       "                            &#x27;dar&#x27;, &#x27;tempo&#x27;, &#x27;fez&#x27;, &#x27;estiveram&#x27;, &#x27;isso&#x27;, &#x27;seria&#x27;,\n",
       "                            &#x27;ai&#x27;, &#x27;de&#x27;, &#x27;tenhamos&#x27;, &#x27;vindo&#x27;, &#x27;vinda&#x27;, &#x27;cuja&#x27;,\n",
       "                            &#x27;seja&#x27;, &#x27;fomos&#x27;, &#x27;ele&#x27;, &#x27;saber&#x27;, &#x27;eles&#x27;, &#x27;teriamos&#x27;,\n",
       "                            &#x27;povo&#x27;, &#x27;as&#x27;, &#x27;maximo&#x27;, &#x27;ambas&#x27;, &#x27;conhecido&#x27;,\n",
       "                            &#x27;devera&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 3),\n",
       "                stop_words=[&#x27;inclusive&#x27;, &#x27;a&#x27;, &#x27;tem&#x27;, &#x27;delas&#x27;, &#x27;pelos&#x27;, &#x27;elas&#x27;,\n",
       "                            &#x27;dar&#x27;, &#x27;tempo&#x27;, &#x27;fez&#x27;, &#x27;estiveram&#x27;, &#x27;isso&#x27;, &#x27;seria&#x27;,\n",
       "                            &#x27;ai&#x27;, &#x27;de&#x27;, &#x27;tenhamos&#x27;, &#x27;vindo&#x27;, &#x27;vinda&#x27;, &#x27;cuja&#x27;,\n",
       "                            &#x27;seja&#x27;, &#x27;fomos&#x27;, &#x27;ele&#x27;, &#x27;saber&#x27;, &#x27;eles&#x27;, &#x27;teriamos&#x27;,\n",
       "                            &#x27;povo&#x27;, &#x27;as&#x27;, &#x27;maximo&#x27;, &#x27;ambas&#x27;, &#x27;conhecido&#x27;,\n",
       "                            &#x27;devera&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 3),\n",
       "                stop_words=['inclusive', 'a', 'tem', 'delas', 'pelos', 'elas',\n",
       "                            'dar', 'tempo', 'fez', 'estiveram', 'isso', 'seria',\n",
       "                            'ai', 'de', 'tenhamos', 'vindo', 'vinda', 'cuja',\n",
       "                            'seja', 'fomos', 'ele', 'saber', 'eles', 'teriamos',\n",
       "                            'povo', 'as', 'maximo', 'ambas', 'conhecido',\n",
       "                            'devera', ...])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords\n",
    "stopwords_nltk = stopwords.words('portuguese')\n",
    "stopwords_spacy = spacy.load('pt_core_news_sm').Defaults.stop_words\n",
    "both_stopwords = set(stopwords_nltk) | set(stopwords_spacy)\n",
    "both_stopwords = list(map(unidecode, both_stopwords))\n",
    "\n",
    "# Create a tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=both_stopwords, max_features=2000,\n",
    "                             ngram_range=(1, 3), min_df=5, max_df=0.8, lowercase=True)\n",
    "\n",
    "# Fit the vectorizer with our texts\n",
    "vectorizer.fit(df_train.norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our texts into vectors\n",
    "X_train = vectorizer.transform(df_train.norm_text)\n",
    "X_val = vectorizer.transform(df_val.norm_text)\n",
    "X_test = vectorizer.transform(df_test.norm_text)\n",
    "\n",
    "y_train = df_train.category\n",
    "y_val = df_val.category\n",
    "y_test = df_test.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((133642, 2000), (16706, 2000), (16705, 2000))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['noites - seg - joesley - aereo - ex diretor - simplesmente - nesses - empreiteira - analisar - renan calheiros',\n",
       " 'investigado - aceitar - casa civil - provavel - iria - expectativas - contexto - longo prazo - vir - julio',\n",
       " 'ajudou - perguntas - juca - codigo - aumentou - gilmar - estimular - inacio - industrial - atuar']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum all the columns\n",
    "X_train_sum = np.sum(X_train, axis=0)\n",
    "\n",
    "# Sort the sum of columns\n",
    "sorted_ngrams = np.asarray(np.argsort(X_train_sum)[::-1]).reshape(-1)\n",
    "\n",
    "# Get the top 10 ngrams\n",
    "top_ngrams = sorted_ngrams[:30]\n",
    "\n",
    "# Get the names of the top 10 ngrams\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# reshape a list into a list of lists with 3 \"rows\"\n",
    "[ \" - \".join(ii) for ii in np.array_split(feature_names[top_ngrams], 3) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             balanced_accuracy_score, classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import (f1_score, balanced_accuracy_score, accuracy_score,\n",
    "                             classification_report, matthews_corrcoef,\n",
    "                             confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_valid, y_valid, n_jobs=-1):\n",
    "    \n",
    "    # Spot Check Algorithms\n",
    "    models = []\n",
    "    models.append(('Calibrated-LSVC', CalibratedClassifierCV(LinearSVC(random_state=314, class_weight='balanced'))))\n",
    "    models.append(('LR', LogisticRegression(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('RF', RandomForestClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('LGBM', LGBMClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('XGB', XGBClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('MLP', MLPClassifier(random_state=314)))\n",
    "    models.append(('SGD', SGDClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('NB', MultinomialNB()))\n",
    "    models.append(('LSVC', LinearSVC(random_state=314, class_weight='balanced')))\n",
    "    models.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "    models.append(('DT', DecisionTreeClassifier(random_state=314, class_weight='balanced')))\n",
    "    \n",
    "    results = []\n",
    "    creports = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_valid)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error {name} - {e}')\n",
    "            continue \n",
    "\n",
    "        f1 = f1_score(y_valid, pred, average='micro')\n",
    "        bacc = balanced_accuracy_score(y_valid, pred)\n",
    "        acc = accuracy_score(y_valid, pred)\n",
    "        cr = classification_report(y_valid, pred)\n",
    "        mcc = matthews_corrcoef(y_valid, pred)\n",
    "        cm = confusion_matrix(y_valid, pred)\n",
    "        creports.append([name, cr, cm])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        results.append([name, f1, bacc, acc, mcc, elapsed, cm, cr])\n",
    "\n",
    "        msg = f'Name: {name} - F1: {f1:.4f} - BACC: {bacc:.4f} - ACC: {acc:.4f} - MCC: {mcc:.4f} - Elapsed: {elapsed:.2f}s'\n",
    "        print(msg)\n",
    "        print(cr)\n",
    "        # print(cm)\n",
    "        # print('*' * 20, '\\n')\n",
    "\n",
    "    columns = ['Model', 'F1', 'BACC', 'ACC', 'MCC', 'Total Time', 'Confusion Matrix', 'Classification Report']\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    df_results['Confusion Matrix'] = df_results['Confusion Matrix'].apply(lambda x: str(x))\n",
    "\n",
    "    return df_results, creports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Calibrated-LSVC - F1: 0.8156 - BACC: 0.7649 - ACC: 0.8156 - MCC: 0.7946 - Elapsed: 98.11s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.73      0.75      2162\n",
      "           1       0.81      0.85      0.83      1697\n",
      "           2       0.77      0.81      0.79       212\n",
      "           3       0.93      0.95      0.94      1973\n",
      "           4       0.78      0.86      0.82      1635\n",
      "           5       0.79      0.83      0.81      2097\n",
      "           6       0.84      0.90      0.87      1713\n",
      "           7       0.94      0.88      0.91       452\n",
      "           8       0.60      0.49      0.54      1136\n",
      "           9       0.99      0.97      0.98       401\n",
      "          10       0.85      0.87      0.86      2203\n",
      "          11       0.77      0.67      0.71       395\n",
      "          12       0.67      0.57      0.62       226\n",
      "          13       0.73      0.62      0.67       190\n",
      "          14       0.80      0.49      0.60       214\n",
      "\n",
      "    accuracy                           0.82     16706\n",
      "   macro avg       0.80      0.76      0.78     16706\n",
      "weighted avg       0.81      0.82      0.81     16706\n",
      "\n",
      "Name: LR - F1: 0.7912 - BACC: 0.8058 - ACC: 0.7912 - MCC: 0.7695 - Elapsed: 31.34s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.65      0.73      2162\n",
      "           1       0.82      0.82      0.82      1697\n",
      "           2       0.62      0.93      0.75       212\n",
      "           3       0.93      0.94      0.94      1973\n",
      "           4       0.78      0.77      0.77      1635\n",
      "           5       0.83      0.76      0.79      2097\n",
      "           6       0.86      0.87      0.87      1713\n",
      "           7       0.85      0.89      0.87       452\n",
      "           8       0.55      0.49      0.52      1136\n",
      "           9       0.97      0.97      0.97       401\n",
      "          10       0.86      0.85      0.86      2203\n",
      "          11       0.61      0.79      0.68       395\n",
      "          12       0.44      0.85      0.58       226\n",
      "          13       0.45      0.79      0.57       190\n",
      "          14       0.38      0.72      0.50       214\n",
      "\n",
      "    accuracy                           0.79     16706\n",
      "   macro avg       0.72      0.81      0.75     16706\n",
      "weighted avg       0.80      0.79      0.79     16706\n",
      "\n",
      "Name: RF - F1: 0.7818 - BACC: 0.7353 - ACC: 0.7818 - MCC: 0.7577 - Elapsed: 875.79s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.66      2162\n",
      "           1       0.74      0.83      0.78      1697\n",
      "           2       0.71      0.86      0.78       212\n",
      "           3       0.87      0.95      0.91      1973\n",
      "           4       0.76      0.84      0.80      1635\n",
      "           5       0.73      0.82      0.78      2097\n",
      "           6       0.79      0.87      0.83      1713\n",
      "           7       0.96      0.85      0.90       452\n",
      "           8       0.70      0.40      0.51      1136\n",
      "           9       0.99      0.94      0.97       401\n",
      "          10       0.78      0.88      0.82      2203\n",
      "          11       0.83      0.62      0.71       395\n",
      "          12       0.68      0.48      0.56       226\n",
      "          13       0.69      0.54      0.61       190\n",
      "          14       0.83      0.55      0.66       214\n",
      "\n",
      "    accuracy                           0.78     16706\n",
      "   macro avg       0.79      0.74      0.75     16706\n",
      "weighted avg       0.78      0.78      0.77     16706\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.808194 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 509934\n",
      "[LightGBM] [Info] Number of data points in the train set: 133642, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "Name: LGBM - F1: 0.8272 - BACC: 0.8266 - ACC: 0.8272 - MCC: 0.8085 - Elapsed: 510.89s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      2162\n",
      "           1       0.83      0.84      0.84      1697\n",
      "           2       0.68      0.90      0.78       212\n",
      "           3       0.95      0.96      0.95      1973\n",
      "           4       0.83      0.86      0.84      1635\n",
      "           5       0.83      0.79      0.81      2097\n",
      "           6       0.86      0.87      0.86      1713\n",
      "           7       0.94      0.89      0.91       452\n",
      "           8       0.61      0.59      0.60      1136\n",
      "           9       0.99      0.97      0.98       401\n",
      "          10       0.87      0.86      0.87      2203\n",
      "          11       0.70      0.79      0.74       395\n",
      "          12       0.50      0.77      0.61       226\n",
      "          13       0.55      0.76      0.64       190\n",
      "          14       0.67      0.80      0.73       214\n",
      "\n",
      "    accuracy                           0.83     16706\n",
      "   macro avg       0.78      0.83      0.80     16706\n",
      "weighted avg       0.83      0.83      0.83     16706\n",
      "\n",
      "[23:33:02] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0fdc6d574b9c0d168-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "Name: XGB - F1: 0.8256 - BACC: 0.7790 - ACC: 0.8256 - MCC: 0.8058 - Elapsed: 1719.91s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      2162\n",
      "           1       0.81      0.85      0.83      1697\n",
      "           2       0.76      0.81      0.78       212\n",
      "           3       0.93      0.96      0.95      1973\n",
      "           4       0.80      0.87      0.83      1635\n",
      "           5       0.80      0.83      0.82      2097\n",
      "           6       0.85      0.88      0.86      1713\n",
      "           7       0.97      0.86      0.91       452\n",
      "           8       0.64      0.55      0.59      1136\n",
      "           9       0.99      0.96      0.98       401\n",
      "          10       0.85      0.88      0.87      2203\n",
      "          11       0.80      0.65      0.72       395\n",
      "          12       0.66      0.58      0.62       226\n",
      "          13       0.73      0.61      0.67       190\n",
      "          14       0.80      0.64      0.71       214\n",
      "\n",
      "    accuracy                           0.83     16706\n",
      "   macro avg       0.81      0.78      0.79     16706\n",
      "weighted avg       0.82      0.83      0.82     16706\n",
      "\n",
      "Name: MLP - F1: 0.8205 - BACC: 0.7759 - ACC: 0.8205 - MCC: 0.8003 - Elapsed: 873.69s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.77      0.79      2162\n",
      "           1       0.84      0.83      0.83      1697\n",
      "           2       0.78      0.78      0.78       212\n",
      "           3       0.94      0.95      0.94      1973\n",
      "           4       0.82      0.84      0.83      1635\n",
      "           5       0.83      0.83      0.83      2097\n",
      "           6       0.83      0.87      0.85      1713\n",
      "           7       0.90      0.90      0.90       452\n",
      "           8       0.56      0.54      0.55      1136\n",
      "           9       0.98      0.96      0.97       401\n",
      "          10       0.86      0.89      0.87      2203\n",
      "          11       0.68      0.69      0.69       395\n",
      "          12       0.57      0.60      0.59       226\n",
      "          13       0.64      0.64      0.64       190\n",
      "          14       0.74      0.56      0.64       214\n",
      "\n",
      "    accuracy                           0.82     16706\n",
      "   macro avg       0.79      0.78      0.78     16706\n",
      "weighted avg       0.82      0.82      0.82     16706\n",
      "\n",
      "Name: SGD - F1: 0.7643 - BACC: 0.7849 - ACC: 0.7643 - MCC: 0.7415 - Elapsed: 2.20s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.46      0.59      2162\n",
      "           1       0.79      0.81      0.80      1697\n",
      "           2       0.52      0.94      0.67       212\n",
      "           3       0.89      0.95      0.92      1973\n",
      "           4       0.75      0.87      0.81      1635\n",
      "           5       0.78      0.76      0.77      2097\n",
      "           6       0.82      0.87      0.85      1713\n",
      "           7       0.74      0.85      0.79       452\n",
      "           8       0.62      0.32      0.42      1136\n",
      "           9       0.95      0.96      0.96       401\n",
      "          10       0.82      0.85      0.84      2203\n",
      "          11       0.57      0.74      0.65       395\n",
      "          12       0.40      0.87      0.55       226\n",
      "          13       0.40      0.85      0.54       190\n",
      "          14       0.46      0.66      0.54       214\n",
      "\n",
      "    accuracy                           0.76     16706\n",
      "   macro avg       0.69      0.78      0.71     16706\n",
      "weighted avg       0.78      0.76      0.76     16706\n",
      "\n",
      "Name: NB - F1: 0.7097 - BACC: 0.6445 - ACC: 0.7097 - MCC: 0.6786 - Elapsed: 0.20s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.34      0.44      2162\n",
      "           1       0.71      0.79      0.75      1697\n",
      "           2       0.69      0.77      0.73       212\n",
      "           3       0.88      0.90      0.89      1973\n",
      "           4       0.66      0.83      0.73      1635\n",
      "           5       0.66      0.77      0.71      2097\n",
      "           6       0.78      0.83      0.80      1713\n",
      "           7       0.88      0.47      0.61       452\n",
      "           8       0.48      0.47      0.47      1136\n",
      "           9       0.99      0.91      0.94       401\n",
      "          10       0.69      0.86      0.76      2203\n",
      "          11       0.70      0.61      0.65       395\n",
      "          12       0.59      0.60      0.59       226\n",
      "          13       0.74      0.51      0.60       190\n",
      "          14       0.88      0.03      0.06       214\n",
      "\n",
      "    accuracy                           0.71     16706\n",
      "   macro avg       0.73      0.64      0.65     16706\n",
      "weighted avg       0.71      0.71      0.69     16706\n",
      "\n",
      "Name: LSVC - F1: 0.8085 - BACC: 0.8026 - ACC: 0.8085 - MCC: 0.7879 - Elapsed: 17.19s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.68      0.74      2162\n",
      "           1       0.82      0.84      0.83      1697\n",
      "           2       0.66      0.88      0.75       212\n",
      "           3       0.93      0.95      0.94      1973\n",
      "           4       0.79      0.84      0.81      1635\n",
      "           5       0.83      0.80      0.81      2097\n",
      "           6       0.84      0.89      0.86      1713\n",
      "           7       0.87      0.90      0.88       452\n",
      "           8       0.59      0.47      0.52      1136\n",
      "           9       0.97      0.97      0.97       401\n",
      "          10       0.87      0.86      0.87      2203\n",
      "          11       0.64      0.76      0.70       395\n",
      "          12       0.53      0.80      0.63       226\n",
      "          13       0.50      0.76      0.60       190\n",
      "          14       0.53      0.65      0.59       214\n",
      "\n",
      "    accuracy                           0.81     16706\n",
      "   macro avg       0.75      0.80      0.77     16706\n",
      "weighted avg       0.81      0.81      0.81     16706\n",
      "\n",
      "Name: KNN - F1: 0.4804 - BACC: 0.4208 - ACC: 0.4804 - MCC: 0.4888 - Elapsed: 2551.24s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.14      0.23      2162\n",
      "           1       0.84      0.51      0.63      1697\n",
      "           2       0.75      0.65      0.70       212\n",
      "           3       0.93      0.66      0.77      1973\n",
      "           4       0.17      0.97      0.29      1635\n",
      "           5       0.87      0.51      0.64      2097\n",
      "           6       0.85      0.42      0.57      1713\n",
      "           7       0.57      0.04      0.08       452\n",
      "           8       0.66      0.18      0.28      1136\n",
      "           9       1.00      0.86      0.92       401\n",
      "          10       0.87      0.58      0.69      2203\n",
      "          11       0.89      0.30      0.45       395\n",
      "          12       0.69      0.26      0.38       226\n",
      "          13       0.76      0.18      0.30       190\n",
      "          14       0.87      0.06      0.11       214\n",
      "\n",
      "    accuracy                           0.48     16706\n",
      "   macro avg       0.76      0.42      0.47     16706\n",
      "weighted avg       0.76      0.48      0.52     16706\n",
      "\n",
      "Name: DT - F1: 0.6096 - BACC: 0.6024 - ACC: 0.6096 - MCC: 0.5658 - Elapsed: 668.65s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.48      0.48      2162\n",
      "           1       0.58      0.61      0.60      1697\n",
      "           2       0.55      0.64      0.59       212\n",
      "           3       0.81      0.80      0.80      1973\n",
      "           4       0.61      0.61      0.61      1635\n",
      "           5       0.57      0.57      0.57      2097\n",
      "           6       0.64      0.65      0.64      1713\n",
      "           7       0.84      0.84      0.84       452\n",
      "           8       0.33      0.30      0.32      1136\n",
      "           9       0.95      0.95      0.95       401\n",
      "          10       0.69      0.68      0.68      2203\n",
      "          11       0.54      0.52      0.53       395\n",
      "          12       0.35      0.38      0.37       226\n",
      "          13       0.40      0.45      0.42       190\n",
      "          14       0.46      0.56      0.50       214\n",
      "\n",
      "    accuracy                           0.61     16706\n",
      "   macro avg       0.59      0.60      0.59     16706\n",
      "weighted avg       0.61      0.61      0.61     16706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results, creports = train_models(X_train, y_train, X_val, y_val, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lula diz que esta lascado mas que ainda tem forca como cabo eleitoral com a possibilidade de uma condenacao impedir sua candidatura em o ex presidente luiz inacio lula da silva fez nesta segunda um discurso inflamado contra a lava jato no qual disse saber que esta lascado exigiu um pedido de desculpas do juiz sergio moro e afirmou que mesmo fora da disputa pelo planalto sera um cabo eleitoral expressivo para a sucessao de michel temer segundo o petista reu em sete acoes penais o objetivo de moro e impedir sua candidatura no ano que vem desidratando o inclusive no apoio a um nome alternativo como o do ex prefeito de sao paulo fernando haddad pt caso ele nao possa concorrer a presidencia eu sei que to lascado todo dia tem um processo eu nao quero nem que moro me absolva eu so quero que ele peca desculpas disse lula durante um seminario sobre educacao em brasilia eles investigadores chegam a dizer ah se o lula nao for candidato ele nao vai ter forca como cabo eleitoral testem completou o petista para o ex presidente moro usou mentiras contadas pela policia federal e pelo ministerio publico para julga lo e condena lo a nove anos e seis meses de prisao pelo caso do triplex em guaruja sp o ex presidente disse ainda nao ter medo dos investigadores que de acordo com ele estao acostumados a mexer com deputados e senadores que temem as apuracoes eu quero que eles saibam o seguinte se eles estao acostumados a lidar com deputado que tem medo deles a mexer com senadores que tem medo deles quero dizer que tenho respeito profundo por quem me respeita pelas leis que nos ajudamos a criar mas nao tenho respeito por quem nao me respeita e eles nao me respeitaram afirmou o petista de acordo com aliados lula nao gosta de discutir mesmo que nos bastidores a chance de nao ser candidato ao planalto e a projecao do nome de haddad como plano b do pt tem incomodado os mais proximos ao ex presidente o ex prefeito que estava no evento nesta segunda fez um discurso rapido de menos de dez minutos em que encerrou dizendo esperar que lula assuma a presidencia em espero que dia o de janeiro de esse pesadelo chamado temer acabe e o senhor assuma a presidencia da republica disse haddad demonio do mercado lula voltou a fazer um discurso mais agressivo em relacao ao mercado e disse que nao tem cara de demonio mas quer que o respeitem como se fosse nao tenho cara de demonio mas quero que eles me respeitem como se eu fosse porque eles sabem que a economia nao vai ficar subordinada ao elitismo da sociedade brasileira disse o ex presidente o petista rivalizou ainda com o deputado jair bolsonaro psc rj segundo colocado nas ultimas pesquisas empatado com marina silva e disse que se ele agrada ao mercado o pt tem que desagradar a folha publicou nesta segunda reportagem em que mostrou que o deputado ensaia movimento ao centro no debate economico adotando um discurso simpatico aos investidores do mercado financeiro '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced.loc[0, \"norm_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>BACC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.827248</td>\n",
       "      <td>0.826563</td>\n",
       "      <td>0.827248</td>\n",
       "      <td>0.808458</td>\n",
       "      <td>510.886407</td>\n",
       "      <td>[[1595   46   10   46   81   94   56   21   95...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.825632</td>\n",
       "      <td>0.779012</td>\n",
       "      <td>0.825632</td>\n",
       "      <td>0.805783</td>\n",
       "      <td>1719.913379</td>\n",
       "      <td>[[1643   45    2   58   86  104   49   12   65...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.820544</td>\n",
       "      <td>0.775940</td>\n",
       "      <td>0.820544</td>\n",
       "      <td>0.800284</td>\n",
       "      <td>873.692021</td>\n",
       "      <td>[[1656   38    6   34   60   83   50   29   96...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calibrated-LSVC</td>\n",
       "      <td>0.815575</td>\n",
       "      <td>0.764922</td>\n",
       "      <td>0.815575</td>\n",
       "      <td>0.794629</td>\n",
       "      <td>98.107174</td>\n",
       "      <td>[[1576   54    4   61   99  128   61   18   68...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVC</td>\n",
       "      <td>0.808512</td>\n",
       "      <td>0.802590</td>\n",
       "      <td>0.808512</td>\n",
       "      <td>0.787885</td>\n",
       "      <td>17.190052</td>\n",
       "      <td>[[1472   56    9   68  108  114   66   40   86...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.791213</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.791213</td>\n",
       "      <td>0.769465</td>\n",
       "      <td>31.342459</td>\n",
       "      <td>[[1416   51   13   72  105  118   62   39  114...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.781815</td>\n",
       "      <td>0.735253</td>\n",
       "      <td>0.781815</td>\n",
       "      <td>0.757670</td>\n",
       "      <td>875.791297</td>\n",
       "      <td>[[1264   72    8  155  115  185   98   17   43...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.764276</td>\n",
       "      <td>0.784948</td>\n",
       "      <td>0.764276</td>\n",
       "      <td>0.741456</td>\n",
       "      <td>2.198763</td>\n",
       "      <td>[[ 986   79   23  156  147  217  108   66   72...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.709685</td>\n",
       "      <td>0.644454</td>\n",
       "      <td>0.709685</td>\n",
       "      <td>0.678643</td>\n",
       "      <td>0.195432</td>\n",
       "      <td>[[ 725   83    9  151  192  385  114   16  165...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.609601</td>\n",
       "      <td>0.602375</td>\n",
       "      <td>0.609601</td>\n",
       "      <td>0.565838</td>\n",
       "      <td>668.646844</td>\n",
       "      <td>[[1028  108   15  126  134  208  119   37  126...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.480366</td>\n",
       "      <td>0.420757</td>\n",
       "      <td>0.480366</td>\n",
       "      <td>0.488760</td>\n",
       "      <td>2551.238596</td>\n",
       "      <td>[[ 296   24    5   52 1573   46   47    5   15...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model        F1      BACC       ACC       MCC   Total Time  \\\n",
       "3              LGBM  0.827248  0.826563  0.827248  0.808458   510.886407   \n",
       "4               XGB  0.825632  0.779012  0.825632  0.805783  1719.913379   \n",
       "5               MLP  0.820544  0.775940  0.820544  0.800284   873.692021   \n",
       "0   Calibrated-LSVC  0.815575  0.764922  0.815575  0.794629    98.107174   \n",
       "8              LSVC  0.808512  0.802590  0.808512  0.787885    17.190052   \n",
       "1                LR  0.791213  0.805785  0.791213  0.769465    31.342459   \n",
       "2                RF  0.781815  0.735253  0.781815  0.757670   875.791297   \n",
       "6               SGD  0.764276  0.784948  0.764276  0.741456     2.198763   \n",
       "7                NB  0.709685  0.644454  0.709685  0.678643     0.195432   \n",
       "10               DT  0.609601  0.602375  0.609601  0.565838   668.646844   \n",
       "9               KNN  0.480366  0.420757  0.480366  0.488760  2551.238596   \n",
       "\n",
       "                                     Confusion Matrix  \\\n",
       "3   [[1595   46   10   46   81   94   56   21   95...   \n",
       "4   [[1643   45    2   58   86  104   49   12   65...   \n",
       "5   [[1656   38    6   34   60   83   50   29   96...   \n",
       "0   [[1576   54    4   61   99  128   61   18   68...   \n",
       "8   [[1472   56    9   68  108  114   66   40   86...   \n",
       "1   [[1416   51   13   72  105  118   62   39  114...   \n",
       "2   [[1264   72    8  155  115  185   98   17   43...   \n",
       "6   [[ 986   79   23  156  147  217  108   66   72...   \n",
       "7   [[ 725   83    9  151  192  385  114   16  165...   \n",
       "10  [[1028  108   15  126  134  208  119   37  126...   \n",
       "9   [[ 296   24    5   52 1573   46   47    5   15...   \n",
       "\n",
       "                                Classification Report  \n",
       "3                 precision    recall  f1-score   ...  \n",
       "4                 precision    recall  f1-score   ...  \n",
       "5                 precision    recall  f1-score   ...  \n",
       "0                 precision    recall  f1-score   ...  \n",
       "8                 precision    recall  f1-score   ...  \n",
       "1                 precision    recall  f1-score   ...  \n",
       "2                 precision    recall  f1-score   ...  \n",
       "6                 precision    recall  f1-score   ...  \n",
       "7                 precision    recall  f1-score   ...  \n",
       "10                precision    recall  f1-score   ...  \n",
       "9                 precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifier Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8247 - BACC: 0.8399 - ACC: 0.8247 - MCC: 0.8064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.75      0.80      2162\n",
      "           1       0.85      0.83      0.84      1697\n",
      "           2       0.62      0.92      0.74       212\n",
      "           3       0.96      0.95      0.95      1973\n",
      "           4       0.84      0.83      0.84      1635\n",
      "           5       0.86      0.78      0.81      2097\n",
      "           6       0.89      0.88      0.88      1713\n",
      "           7       0.89      0.92      0.90       452\n",
      "           8       0.61      0.54      0.57      1136\n",
      "           9       0.98      0.98      0.98       401\n",
      "          10       0.89      0.87      0.88      2203\n",
      "          11       0.64      0.82      0.72       395\n",
      "          12       0.41      0.88      0.56       226\n",
      "          13       0.48      0.84      0.61       190\n",
      "          14       0.51      0.82      0.63       214\n",
      "\n",
      "    accuracy                           0.82     16706\n",
      "   macro avg       0.75      0.84      0.78     16706\n",
      "weighted avg       0.84      0.82      0.83     16706\n",
      "\n",
      "[[1611   44   11   34   81   76   44   45   96    1   56   17   17   15\n",
      "    14]\n",
      " [  15 1414   34    8   18   22   18    0   44    2   43   22   11   21\n",
      "    25]\n",
      " [   1    7  196    0    0    1    0    0    3    0    3    0    1    0\n",
      "     0]\n",
      " [  16   10    0 1875    2    6   15    0   11    0    9    2    6   10\n",
      "    11]\n",
      " [  40   17    3    4 1365    4   13    0   69    2    9   41   28   14\n",
      "    26]\n",
      " [  51   34   13    2    7 1628   26    2   61    1   81    9  144   26\n",
      "    12]\n",
      " [  27    9    5    4   24   23 1504    3   45    0   11    0   18   24\n",
      "    16]\n",
      " [  13    6    5    1    1    2    3  416    2    0    3    0    0    0\n",
      "     0]\n",
      " [  52   44   27   18   84   41   40    1  615    3    6   76   45   53\n",
      "    31]\n",
      " [   2    0    0    0    4    0    0    0    0  392    0    0    0    0\n",
      "     3]\n",
      " [  45   58   16    4    6   87   24    3   12    1 1907    2    6    3\n",
      "    29]\n",
      " [   4   10    3    0   18    0    0    0   28    0    0  322    2    6\n",
      "     2]\n",
      " [   2    1    1    2    1    7    4    0    6    0    0    2  198    1\n",
      "     1]\n",
      " [   3    1    0    1    6    0    2    0   10    0    0    5    2  160\n",
      "     0]\n",
      " [   0    3    2    7    4    2    5    0    7    0    6    2    0    1\n",
      "   175]]\n"
     ]
    }
   ],
   "source": [
    "model_lsvc = LinearSVC(random_state=seed, class_weight='balanced')\n",
    "model_calibrated_lsvc = CalibratedClassifierCV(LinearSVC(random_state=seed, class_weight='balanced'))\n",
    "model_lgbm = LGBMClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "estimators = [\n",
    "                ('lsvc', model_lsvc),\n",
    "                ('calibrated_lsvc', model_calibrated_lsvc),\n",
    "                ('lgbm', model_lgbm)\n",
    "            ]\n",
    "\n",
    "model_stacked = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=seed, n_jobs=-1, class_weight='balanced'), n_jobs=2, cv=5)\n",
    "\n",
    "model_stacked.fit(X_train, y_train)\n",
    "\n",
    "pred = model_stacked.predict(X_val)\n",
    "\n",
    "f1 = f1_score(y_val, pred, average='micro')\n",
    "bacc = balanced_accuracy_score(y_val, pred)\n",
    "acc = accuracy_score(y_val, pred)\n",
    "cr = classification_report(y_val, pred)\n",
    "mcc = matthews_corrcoef(y_val, pred)\n",
    "cm = confusion_matrix(y_val, pred)\n",
    "\n",
    "print(f'F1: {f1:.4f} - BACC: {bacc:.4f} - ACC: {acc:.4f} - MCC: {mcc:.4f}')\n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "# Took 1.5 minute to run in a 48 core CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.683333333333334"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=314, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter grid for the search\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object with the SGDClassifier and parameter grid\n",
    "grid_search = GridSearchCV(model_sgd, param_grid, cv=3, scoring=scorer_mcc, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search by fitting training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MCC score found by the grid search\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with chosen parameters on the test set\n",
    "best_estimator = grid_search.best_estimator_\n",
    "valid_mcc = best_estimator.score(X_val, y_val)\n",
    "print(\"Valid MCC: \", valid_mcc)\n",
    "\n",
    "# Took 65 minutes to run in a 48 core CPU\n",
    "# it performs 4 * 5 * 5 * 3 combinations of parameters, which is 300 combinations in total. Since it uses Cross Validation with 3 folds, it will train 900 models in total!!!!!\n",
    "\n",
    "# Best parameters:  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1'}\n",
    "# Best score:  0.8971782029568908\n",
    "# Valid MCC:  0.9570773263433814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=314, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter grid for the search\n",
    "param_dist = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object with the SGDClassifier and parameter distribution\n",
    "random_search = RandomizedSearchCV(model_sgd, param_dist, cv=3, scoring=scorer_mcc, \n",
    "                                   n_jobs=-1, n_iter=60, random_state=314)\n",
    "\n",
    "# Perform the random search by fitting training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MCC score found by the random search\n",
    "print(\"Best parameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the model with chosen parameters on the test set\n",
    "best_estimator = random_search.best_estimator_\n",
    "valid_mcc = best_estimator.score(X_val, y_val)\n",
    "print(\"Valid MCC: \", valid_mcc)\n",
    "\n",
    "# This will typically run faster than GridSearchCV due to the reduced number of parameter combinations.\n",
    "# Time to run: 26 minutes in a 48 core CPU\n",
    "# Best parameters:  {'penalty': 'elasticnet', 'max_iter': 2000, 'loss': 'modified_huber', 'alpha': 0.0001}\n",
    "# Best score:  0.9068535026549907\n",
    "# Valid MCC:  0.963302752293578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing Bayesian Optimization for Hyperparameter Tuning\n",
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=314, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter search space for the optimizer\n",
    "param_space = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "# Create the BayesSearchCV object with the SGDClassifier and parameter distribution\n",
    "bayes_search = BayesSearchCV(model_sgd, param_space, cv=3, scoring=scorer_mcc, \n",
    "                             n_jobs=-1, n_iter=30, random_state=314)\n",
    "\n",
    "# Perform the Bayesian optimization by fitting training data\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MCC score found by the Bayesian search\n",
    "print(\"Best parameters: \", bayes_search.best_params_)\n",
    "print(\"Best score: \", bayes_search.best_score_)\n",
    "\n",
    "# Evaluate the model with chosen parameters on the test set\n",
    "best_estimator = bayes_search.best_estimator_\n",
    "valid_mcc = best_estimator.score(X_val, y_val)\n",
    "print(\"Valid MCC: \", valid_mcc)\n",
    "\n",
    "# Time to run: 36 minutes in a 48 core CPU\n",
    "# Best parameters:  OrderedDict([('alpha', 0.0001), ('loss', 'modified_huber'), ('max_iter', 2000), ('penalty', 'elasticnet')])\n",
    "# Best score:  0.9068535026549907\n",
    "# Valid MCC:  0.963302752293578"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
