{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A string\n",
    "\n",
    "    Returns:\n",
    "        str: string without punctuation\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z\\d\\s]', ' ', text)\n",
    "\n",
    "def remove_multiple_blank_spaces(text):\n",
    "    \"\"\"Remove multiple blank spaces from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A string\n",
    "\n",
    "    Returns:\n",
    "        str: string with only one space between words\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "1         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "2         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "3         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/10/1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "data = pd.read_csv(\"Input/archive.zip\", low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "text              765\n",
       "date                0\n",
       "category            0\n",
       "subcategory    137418\n",
       "link                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count empty values by columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poder</th>\n",
       "      <td>22022</td>\n",
       "      <td>22022</td>\n",
       "      <td>22022</td>\n",
       "      <td>939</td>\n",
       "      <td>22022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colunas</th>\n",
       "      <td>21622</td>\n",
       "      <td>21619</td>\n",
       "      <td>21622</td>\n",
       "      <td>21622</td>\n",
       "      <td>21622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercado</th>\n",
       "      <td>20970</td>\n",
       "      <td>20970</td>\n",
       "      <td>20970</td>\n",
       "      <td>0</td>\n",
       "      <td>20970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esporte</th>\n",
       "      <td>19730</td>\n",
       "      <td>19730</td>\n",
       "      <td>19730</td>\n",
       "      <td>2859</td>\n",
       "      <td>19730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mundo</th>\n",
       "      <td>17130</td>\n",
       "      <td>17130</td>\n",
       "      <td>17130</td>\n",
       "      <td>0</td>\n",
       "      <td>17130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cotidiano</th>\n",
       "      <td>16967</td>\n",
       "      <td>16967</td>\n",
       "      <td>16967</td>\n",
       "      <td>35</td>\n",
       "      <td>16967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrada</th>\n",
       "      <td>16345</td>\n",
       "      <td>15617</td>\n",
       "      <td>16345</td>\n",
       "      <td>0</td>\n",
       "      <td>16345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opiniao</th>\n",
       "      <td>4525</td>\n",
       "      <td>4525</td>\n",
       "      <td>4525</td>\n",
       "      <td>0</td>\n",
       "      <td>4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paineldoleitor</th>\n",
       "      <td>4011</td>\n",
       "      <td>4011</td>\n",
       "      <td>4011</td>\n",
       "      <td>260</td>\n",
       "      <td>4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saopaulo</th>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>471</td>\n",
       "      <td>3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tec</th>\n",
       "      <td>2260</td>\n",
       "      <td>2260</td>\n",
       "      <td>2260</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>2142</td>\n",
       "      <td>2123</td>\n",
       "      <td>2142</td>\n",
       "      <td>2142</td>\n",
       "      <td>2142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educacao</th>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "      <td>0</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turismo</th>\n",
       "      <td>1903</td>\n",
       "      <td>1903</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrissima</th>\n",
       "      <td>1411</td>\n",
       "      <td>1409</td>\n",
       "      <td>1411</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciencia</th>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>0</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equilibrioesaude</th>\n",
       "      <td>1312</td>\n",
       "      <td>1312</td>\n",
       "      <td>1312</td>\n",
       "      <td>0</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sobretudo</th>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folhinha</th>\n",
       "      <td>876</td>\n",
       "      <td>875</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empreendedorsocial</th>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>150</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comida</th>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asmais</th>\n",
       "      <td>548</td>\n",
       "      <td>547</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambiente</th>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seminariosfolha</th>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serafina</th>\n",
       "      <td>334</td>\n",
       "      <td>331</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o-melhor-de-sao-paulo</th>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>71</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vice</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guia-de-livros-discos-filmes</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topofmind</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banco-de-dados</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>especial</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infograficos</th>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cenarios-2017</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfi</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guia-de-livros-filmes-discos</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multimidia</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treinamento</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treinamentocienciaesaude</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mulher</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euronews</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ombudsman</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contas-de-casa</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bichos</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musica</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title   text   date  subcategory   link\n",
       "category                                                             \n",
       "poder                         22022  22022  22022          939  22022\n",
       "colunas                       21622  21619  21622        21622  21622\n",
       "mercado                       20970  20970  20970            0  20970\n",
       "esporte                       19730  19730  19730         2859  19730\n",
       "mundo                         17130  17130  17130            0  17130\n",
       "cotidiano                     16967  16967  16967           35  16967\n",
       "ilustrada                     16345  15617  16345            0  16345\n",
       "opiniao                        4525   4525   4525            0   4525\n",
       "paineldoleitor                 4011   4011   4011          260   4011\n",
       "saopaulo                       3955   3955   3955          471   3955\n",
       "tec                            2260   2260   2260            0   2260\n",
       "tv                             2142   2123   2142         2142   2142\n",
       "educacao                       2118   2118   2118            0   2118\n",
       "turismo                        1903   1903   1903            0   1903\n",
       "ilustrissima                   1411   1409   1411            0   1411\n",
       "ciencia                        1335   1335   1335            0   1335\n",
       "equilibrioesaude               1312   1312   1312            0   1312\n",
       "sobretudo                      1057   1057   1057         1057   1057\n",
       "bbc                             980    980    980            0    980\n",
       "folhinha                        876    875    876            0    876\n",
       "empreendedorsocial              841    841    841          150    841\n",
       "comida                          828    828    828            0    828\n",
       "asmais                          548    547    548            0    548\n",
       "ambiente                        491    491    491            0    491\n",
       "seminariosfolha                 379    379    379            0    379\n",
       "serafina                        334    331    334            0    334\n",
       "o-melhor-de-sao-paulo           189    189    189           71    189\n",
       "vice                            146    146    146            0    146\n",
       "guia-de-livros-discos-filmes    143    143    143            0    143\n",
       "topofmind                        86     86     86            0     86\n",
       "banco-de-dados                   64     64     64            0     64\n",
       "dw                               48     48     48            0     48\n",
       "especial                         43     43     43            0     43\n",
       "infograficos                     43     40     43            0     43\n",
       "cenarios-2017                    43     43     43            0     43\n",
       "rfi                              29     29     29            0     29\n",
       "guia-de-livros-filmes-discos     28     28     28            0     28\n",
       "multimidia                       27     27     27           27     27\n",
       "treinamento                      21     21     21            0     21\n",
       "treinamentocienciaesaude         18     18     18            0     18\n",
       "mulher                           16     16     16            0     16\n",
       "euronews                          8      8      8            0      8\n",
       "ombudsman                         3      3      3            0      3\n",
       "contas-de-casa                    2      0      2            2      2\n",
       "2016                              1      0      1            0      1\n",
       "bichos                            1      1      1            0      1\n",
       "musica                            1      0      1            0      1\n",
       "2015                              1      0      1            0      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count items by category\n",
    "data.groupby(\"category\").count().sort_values(by=\"title\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 166092 entries, 0 to 167052\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        166092 non-null  object\n",
      " 1   text         165335 non-null  object\n",
      " 2   date         166092 non-null  object\n",
      " 3   category     166092 non-null  object\n",
      " 4   subcategory  29535 non-null   object\n",
      " 5   link         166092 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 8.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# To avoid unbalanced data, we will remove the categories with less than 300 items\n",
    "categories_mask = data[\"category\"].value_counts() > 300\n",
    "categories_mask = categories_mask[categories_mask.values].index\n",
    "# Filter data\n",
    "mask = data[\"category\"].isin(categories_mask)\n",
    "data_filtered = data[mask]\n",
    "data_filtered.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ambiente              300\n",
       "asmais                300\n",
       "turismo               300\n",
       "tec                   300\n",
       "sobretudo             300\n",
       "serafina              300\n",
       "seminariosfolha       300\n",
       "saopaulo              300\n",
       "poder                 300\n",
       "paineldoleitor        300\n",
       "opiniao               300\n",
       "mundo                 300\n",
       "mercado               300\n",
       "ilustrissima          300\n",
       "ilustrada             300\n",
       "folhinha              300\n",
       "esporte               300\n",
       "equilibrioesaude      300\n",
       "empreendedorsocial    300\n",
       "educacao              300\n",
       "cotidiano             300\n",
       "comida                300\n",
       "colunas               300\n",
       "ciencia               300\n",
       "bbc                   300\n",
       "tv                    300\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 333\n",
    "data_balanced = data_filtered.groupby('category').apply(lambda x: x.sample(300, random_state=seed))\n",
    "\n",
    "# Store the unused data for future use\n",
    "balanced_index = set(data_balanced.unstack(level=0).index)\n",
    "balanced_categories = data_balanced.category.unique()\n",
    "mask = ~(data_filtered.index.isin(balanced_index)) & (data_filtered.category.isin(balanced_categories))\n",
    "data_unbalanced = data_filtered[mask].reset_index(drop=True)\n",
    "\n",
    "# Balanced data\n",
    "data_balanced.reset_index(drop=True, inplace=True)\n",
    "data_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Após 20 anos, presença do raro gavião-real é r...</td>\n",
       "      <td>apos 20 anos presenca do raro gaviao real e re...</td>\n",
       "      <td>ambiente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aumento do nível do mar pode estar a caminho, ...</td>\n",
       "      <td>aumento do nivel do mar pode estar a caminho d...</td>\n",
       "      <td>ambiente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Temer revoga decreto sobre reserva mineral e a...</td>\n",
       "      <td>temer revoga decreto sobre reserva mineral e a...</td>\n",
       "      <td>ambiente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Poluição é uma das ameaças à beleza natural da...</td>\n",
       "      <td>poluicao e uma das ameacas a beleza natural da...</td>\n",
       "      <td>ambiente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fernando de Noronha vira laboratório de negóci...</td>\n",
       "      <td>fernando de noronha vira laboratorio de negoci...</td>\n",
       "      <td>ambiente</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Após 20 anos, presença do raro gavião-real é r...   \n",
       "1  Aumento do nível do mar pode estar a caminho, ...   \n",
       "2  Temer revoga decreto sobre reserva mineral e a...   \n",
       "3  Poluição é uma das ameaças à beleza natural da...   \n",
       "4  Fernando de Noronha vira laboratório de negóci...   \n",
       "\n",
       "                                           norm_text  category  \n",
       "0  apos 20 anos presenca do raro gaviao real e re...  ambiente  \n",
       "1  aumento do nivel do mar pode estar a caminho d...  ambiente  \n",
       "2  temer revoga decreto sobre reserva mineral e a...  ambiente  \n",
       "3  poluicao e uma das ameacas a beleza natural da...  ambiente  \n",
       "4  fernando de noronha vira laboratorio de negoci...  ambiente  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining text and title\n",
    "df_balanced = data_balanced[[\"title\", \"text\", \"category\"]].copy()\n",
    "df_balanced[\"full_text\"] = df_balanced[\"title\"] + \" \" + df_balanced[\"text\"]\n",
    "# Text cleaning\n",
    "df_balanced[\"norm_text\"] = df_balanced.full_text.apply(lambda x: remove_multiple_blank_spaces(\n",
    "                                                remove_punctuation(\n",
    "                                                    unidecode(str(x).lower())\n",
    "                                                )\n",
    "                                            ))\n",
    "df_balanced = df_balanced[[\"full_text\", \"norm_text\", \"category\"]]\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change category to numeric\n",
    "df_balanced[\"category\"] = df_balanced.category.astype(\"category\")\n",
    "# df_balanced.category = df_balanced.category.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6240, 3), (780, 3), (780, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_balanced, test_size=0.2, random_state=314, stratify=df_balanced.category)\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.5, random_state=314, stratify=df_test.category)\n",
    "\n",
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words and vectorization\n",
    "\n",
    " [ ] Conferir a questão das stopwords não funcionarem por causa da lingua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 2),\n",
       "                stop_words=[&#x27;a&#x27;, &#x27;à&#x27;, &#x27;ao&#x27;, &#x27;aos&#x27;, &#x27;aquela&#x27;, &#x27;aquelas&#x27;,\n",
       "                            &#x27;aquele&#x27;, &#x27;aqueles&#x27;, &#x27;aquilo&#x27;, &#x27;as&#x27;, &#x27;às&#x27;, &#x27;até&#x27;,\n",
       "                            &#x27;com&#x27;, &#x27;como&#x27;, &#x27;da&#x27;, &#x27;das&#x27;, &#x27;de&#x27;, &#x27;dela&#x27;, &#x27;delas&#x27;,\n",
       "                            &#x27;dele&#x27;, &#x27;deles&#x27;, &#x27;depois&#x27;, &#x27;do&#x27;, &#x27;dos&#x27;, &#x27;e&#x27;, &#x27;é&#x27;,\n",
       "                            &#x27;ela&#x27;, &#x27;elas&#x27;, &#x27;ele&#x27;, &#x27;eles&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 2),\n",
       "                stop_words=[&#x27;a&#x27;, &#x27;à&#x27;, &#x27;ao&#x27;, &#x27;aos&#x27;, &#x27;aquela&#x27;, &#x27;aquelas&#x27;,\n",
       "                            &#x27;aquele&#x27;, &#x27;aqueles&#x27;, &#x27;aquilo&#x27;, &#x27;as&#x27;, &#x27;às&#x27;, &#x27;até&#x27;,\n",
       "                            &#x27;com&#x27;, &#x27;como&#x27;, &#x27;da&#x27;, &#x27;das&#x27;, &#x27;de&#x27;, &#x27;dela&#x27;, &#x27;delas&#x27;,\n",
       "                            &#x27;dele&#x27;, &#x27;deles&#x27;, &#x27;depois&#x27;, &#x27;do&#x27;, &#x27;dos&#x27;, &#x27;e&#x27;, &#x27;é&#x27;,\n",
       "                            &#x27;ela&#x27;, &#x27;elas&#x27;, &#x27;ele&#x27;, &#x27;eles&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 2),\n",
       "                stop_words=['a', 'à', 'ao', 'aos', 'aquela', 'aquelas',\n",
       "                            'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até',\n",
       "                            'com', 'como', 'da', 'das', 'de', 'dela', 'delas',\n",
       "                            'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é',\n",
       "                            'ela', 'elas', 'ele', 'eles', ...])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords\n",
    "stopwords_nltk = stopwords.words('portuguese')\n",
    "# stopwords_spacy = spacy.load('pt_core_news_sm').Defaults.stop_words\n",
    "# both_stopwords = set(stopwords_nltk) | set(stopwords_spacy)\n",
    "\n",
    "# Create a tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_nltk, max_features=2000,\n",
    "                             ngram_range=(1, 2), min_df=5, max_df=0.8, lowercase=True)\n",
    "\n",
    "# Fit the vectorizer with our texts\n",
    "vectorizer.fit(df_train.norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform our texts into vectors\n",
    "X_train = vectorizer.transform(df_train.norm_text)\n",
    "X_val = vectorizer.transform(df_val.norm_text)\n",
    "X_test = vectorizer.transform(df_test.norm_text)\n",
    "\n",
    "y_train = df_train.category\n",
    "y_val = df_val.category\n",
    "y_test = df_test.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6240, 2000), (780, 2000), (780, 2000))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acha - universidade federal - porque nao - codigo - to - passeios - nao existe - teoria - avanco - boa parte',\n",
       " 'justamente - ruim - empregos - trabalhando - clara - falou - considera - longo prazo - recentes - 2004',\n",
       " 'mercados - depende - estaduais - falando - tentando - 75 - pensamento - fiquei - influencia - existencia']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum all the columns\n",
    "X_train_sum = np.sum(X_train, axis=0)\n",
    "\n",
    "# Sort the sum of columns\n",
    "sorted_ngrams = np.asarray(np.argsort(X_train_sum)[::-1]).reshape(-1)\n",
    "\n",
    "# Get the top 10 ngrams\n",
    "top_ngrams = sorted_ngrams[:30]\n",
    "\n",
    "# Get the names of the top 10 ngrams\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# reshape a list into a list of lists with 3 \"rows\"\n",
    "[ \" - \".join(ii) for ii in np.array_split(feature_names[top_ngrams], 3) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             balanced_accuracy_score, classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import (f1_score, balanced_accuracy_score, accuracy_score,\n",
    "                             classification_report, matthews_corrcoef,\n",
    "                             confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_valid, y_valid, n_jobs=-1):\n",
    "    \n",
    "    # Spot Check Algorithms\n",
    "    models = []\n",
    "    models.append(('Calibrated-LSVC', CalibratedClassifierCV(LinearSVC(random_state=314, class_weight='balanced'))))\n",
    "    models.append(('LR', LogisticRegression(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('RF', RandomForestClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('LGBM', LGBMClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('XGB', XGBClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('MLP', MLPClassifier(random_state=314)))\n",
    "    models.append(('SGD', SGDClassifier(random_state=314, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('NB', MultinomialNB()))\n",
    "    models.append(('LSVC', LinearSVC(random_state=314, class_weight='balanced')))\n",
    "    models.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "    models.append(('DT', DecisionTreeClassifier(random_state=314, class_weight='balanced')))\n",
    "    \n",
    "    results = []\n",
    "    creports = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_valid)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error {name} - {e}')\n",
    "            continue \n",
    "\n",
    "        f1 = f1_score(y_valid, pred, average='micro')\n",
    "        bacc = balanced_accuracy_score(y_valid, pred)\n",
    "        acc = accuracy_score(y_valid, pred)\n",
    "        cr = classification_report(y_valid, pred)\n",
    "        mcc = matthews_corrcoef(y_valid, pred)\n",
    "        cm = confusion_matrix(y_valid, pred)\n",
    "        creports.append([name, cr, cm])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        results.append([name, f1, bacc, acc, mcc, elapsed, cm, cr])\n",
    "\n",
    "        msg = f'Name: {name} - F1: {f1:.4f} - BACC: {bacc:.4f} - ACC: {acc:.4f} - MCC: {mcc:.4f} - Elapsed: {elapsed:.2f}s'\n",
    "        print(msg)\n",
    "        print(cr)\n",
    "        # print(cm)\n",
    "        # print('*' * 20, '\\n')\n",
    "\n",
    "    columns = ['Model', 'F1', 'BACC', 'ACC', 'MCC', 'Total Time', 'Confusion Matrix', 'Classification Report']\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    df_results['Confusion Matrix'] = df_results['Confusion Matrix'].apply(lambda x: str(x))\n",
    "\n",
    "    return df_results, creports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Calibrated-LSVC - F1: 0.6859 - BACC: 0.6859 - ACC: 0.6859 - MCC: 0.6737 - Elapsed: 3.57s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.76      0.73      0.75        30\n",
      "            asmais       0.40      0.27      0.32        30\n",
      "               bbc       0.45      0.33      0.38        30\n",
      "           ciencia       0.61      0.73      0.67        30\n",
      "           colunas       0.44      0.27      0.33        30\n",
      "            comida       0.71      0.80      0.75        30\n",
      "         cotidiano       0.67      0.67      0.67        30\n",
      "          educacao       0.77      0.90      0.83        30\n",
      "empreendedorsocial       0.88      0.77      0.82        30\n",
      "  equilibrioesaude       0.52      0.50      0.51        30\n",
      "           esporte       0.77      0.80      0.79        30\n",
      "          folhinha       0.77      0.77      0.77        30\n",
      "         ilustrada       0.62      0.53      0.57        30\n",
      "      ilustrissima       0.71      0.73      0.72        30\n",
      "           mercado       0.67      0.60      0.63        30\n",
      "             mundo       0.66      0.83      0.74        30\n",
      "           opiniao       0.77      0.80      0.79        30\n",
      "    paineldoleitor       1.00      0.97      0.98        30\n",
      "             poder       0.77      0.80      0.79        30\n",
      "          saopaulo       0.64      0.60      0.62        30\n",
      "   seminariosfolha       0.76      0.83      0.79        30\n",
      "          serafina       0.53      0.77      0.63        30\n",
      "         sobretudo       0.71      0.83      0.77        30\n",
      "               tec       0.72      0.77      0.74        30\n",
      "           turismo       0.82      0.77      0.79        30\n",
      "                tv       0.50      0.47      0.48        30\n",
      "\n",
      "          accuracy                           0.69       780\n",
      "         macro avg       0.68      0.69      0.68       780\n",
      "      weighted avg       0.68      0.69      0.68       780\n",
      "\n",
      "Name: LR - F1: 0.6833 - BACC: 0.6833 - ACC: 0.6833 - MCC: 0.6712 - Elapsed: 3.67s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.71      0.80      0.75        30\n",
      "            asmais       0.47      0.23      0.31        30\n",
      "               bbc       0.43      0.33      0.38        30\n",
      "           ciencia       0.73      0.63      0.68        30\n",
      "           colunas       0.38      0.20      0.26        30\n",
      "            comida       0.72      0.77      0.74        30\n",
      "         cotidiano       0.54      0.67      0.60        30\n",
      "          educacao       0.76      0.93      0.84        30\n",
      "empreendedorsocial       0.87      0.67      0.75        30\n",
      "  equilibrioesaude       0.58      0.73      0.65        30\n",
      "           esporte       0.78      0.83      0.81        30\n",
      "          folhinha       0.74      0.67      0.70        30\n",
      "         ilustrada       0.68      0.63      0.66        30\n",
      "      ilustrissima       0.68      0.70      0.69        30\n",
      "           mercado       0.61      0.57      0.59        30\n",
      "             mundo       0.66      0.83      0.74        30\n",
      "           opiniao       0.73      0.73      0.73        30\n",
      "    paineldoleitor       1.00      0.93      0.97        30\n",
      "             poder       0.79      0.77      0.78        30\n",
      "          saopaulo       0.61      0.63      0.62        30\n",
      "   seminariosfolha       0.74      0.77      0.75        30\n",
      "          serafina       0.60      0.70      0.65        30\n",
      "         sobretudo       0.68      0.87      0.76        30\n",
      "               tec       0.76      0.83      0.79        30\n",
      "           turismo       0.81      0.83      0.82        30\n",
      "                tv       0.52      0.50      0.51        30\n",
      "\n",
      "          accuracy                           0.68       780\n",
      "         macro avg       0.68      0.68      0.67       780\n",
      "      weighted avg       0.68      0.68      0.67       780\n",
      "\n",
      "Name: RF - F1: 0.6692 - BACC: 0.6692 - ACC: 0.6692 - MCC: 0.6570 - Elapsed: 9.29s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.82      0.47      0.60        30\n",
      "            asmais       0.67      0.20      0.31        30\n",
      "               bbc       0.60      0.40      0.48        30\n",
      "           ciencia       0.49      0.60      0.54        30\n",
      "           colunas       0.60      0.30      0.40        30\n",
      "            comida       0.73      0.73      0.73        30\n",
      "         cotidiano       0.59      0.67      0.62        30\n",
      "          educacao       0.71      0.97      0.82        30\n",
      "empreendedorsocial       0.85      0.73      0.79        30\n",
      "  equilibrioesaude       0.51      0.63      0.57        30\n",
      "           esporte       0.68      0.83      0.75        30\n",
      "          folhinha       0.78      0.60      0.68        30\n",
      "         ilustrada       0.57      0.43      0.49        30\n",
      "      ilustrissima       0.74      0.77      0.75        30\n",
      "           mercado       0.62      0.60      0.61        30\n",
      "             mundo       0.62      0.77      0.69        30\n",
      "           opiniao       0.90      0.87      0.88        30\n",
      "    paineldoleitor       1.00      0.93      0.97        30\n",
      "             poder       0.58      0.73      0.65        30\n",
      "          saopaulo       0.69      0.67      0.68        30\n",
      "   seminariosfolha       0.67      0.67      0.67        30\n",
      "          serafina       0.62      0.70      0.66        30\n",
      "         sobretudo       0.53      0.83      0.65        30\n",
      "               tec       0.71      0.90      0.79        30\n",
      "           turismo       0.81      0.87      0.84        30\n",
      "                tv       0.55      0.53      0.54        30\n",
      "\n",
      "          accuracy                           0.67       780\n",
      "         macro avg       0.68      0.67      0.66       780\n",
      "      weighted avg       0.68      0.67      0.66       780\n",
      "\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.060401 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 209930\n",
      "[LightGBM] [Info] Number of data points in the train set: 6240, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Info] Start training from score -3.258097\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Name: LGBM - F1: 0.6949 - BACC: 0.6949 - ACC: 0.6949 - MCC: 0.6830 - Elapsed: 88.75s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.78      0.70      0.74        30\n",
      "            asmais       0.45      0.43      0.44        30\n",
      "               bbc       0.60      0.60      0.60        30\n",
      "           ciencia       0.55      0.57      0.56        30\n",
      "           colunas       0.46      0.37      0.41        30\n",
      "            comida       0.69      0.73      0.71        30\n",
      "         cotidiano       0.67      0.67      0.67        30\n",
      "          educacao       0.71      0.90      0.79        30\n",
      "empreendedorsocial       1.00      0.70      0.82        30\n",
      "  equilibrioesaude       0.53      0.67      0.59        30\n",
      "           esporte       0.82      0.77      0.79        30\n",
      "          folhinha       0.86      0.80      0.83        30\n",
      "         ilustrada       0.48      0.50      0.49        30\n",
      "      ilustrissima       0.70      0.77      0.73        30\n",
      "           mercado       0.58      0.63      0.60        30\n",
      "             mundo       0.74      0.77      0.75        30\n",
      "           opiniao       0.93      0.87      0.90        30\n",
      "    paineldoleitor       0.97      0.93      0.95        30\n",
      "             poder       0.79      0.63      0.70        30\n",
      "          saopaulo       0.69      0.60      0.64        30\n",
      "   seminariosfolha       0.72      0.60      0.65        30\n",
      "          serafina       0.62      0.67      0.65        30\n",
      "         sobretudo       0.74      0.83      0.78        30\n",
      "               tec       0.68      0.90      0.77        30\n",
      "           turismo       0.80      0.80      0.80        30\n",
      "                tv       0.71      0.67      0.69        30\n",
      "\n",
      "          accuracy                           0.69       780\n",
      "         macro avg       0.70      0.69      0.69       780\n",
      "      weighted avg       0.70      0.69      0.69       780\n",
      "\n",
      "Error XGB - Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25], got ['ambiente' 'asmais' 'bbc' 'ciencia' 'colunas' 'comida' 'cotidiano'\n",
      " 'educacao' 'empreendedorsocial' 'equilibrioesaude' 'esporte' 'folhinha'\n",
      " 'ilustrada' 'ilustrissima' 'mercado' 'mundo' 'opiniao' 'paineldoleitor'\n",
      " 'poder' 'saopaulo' 'seminariosfolha' 'serafina' 'sobretudo' 'tec'\n",
      " 'turismo' 'tv']\n",
      "Name: MLP - F1: 0.6846 - BACC: 0.6846 - ACC: 0.6846 - MCC: 0.6722 - Elapsed: 59.60s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.76      0.73      0.75        30\n",
      "            asmais       0.34      0.33      0.34        30\n",
      "               bbc       0.48      0.37      0.42        30\n",
      "           ciencia       0.59      0.67      0.62        30\n",
      "           colunas       0.32      0.23      0.27        30\n",
      "            comida       0.73      0.80      0.76        30\n",
      "         cotidiano       0.69      0.67      0.68        30\n",
      "          educacao       0.80      0.93      0.86        30\n",
      "empreendedorsocial       0.88      0.77      0.82        30\n",
      "  equilibrioesaude       0.50      0.47      0.48        30\n",
      "           esporte       0.79      0.77      0.78        30\n",
      "          folhinha       0.81      0.70      0.75        30\n",
      "         ilustrada       0.50      0.57      0.53        30\n",
      "      ilustrissima       0.67      0.73      0.70        30\n",
      "           mercado       0.62      0.60      0.61        30\n",
      "             mundo       0.74      0.83      0.78        30\n",
      "           opiniao       0.83      0.83      0.83        30\n",
      "    paineldoleitor       1.00      0.97      0.98        30\n",
      "             poder       0.85      0.73      0.79        30\n",
      "          saopaulo       0.67      0.60      0.63        30\n",
      "   seminariosfolha       0.73      0.80      0.76        30\n",
      "          serafina       0.54      0.70      0.61        30\n",
      "         sobretudo       0.74      0.83      0.78        30\n",
      "               tec       0.78      0.83      0.81        30\n",
      "           turismo       0.79      0.73      0.76        30\n",
      "                tv       0.62      0.60      0.61        30\n",
      "\n",
      "          accuracy                           0.68       780\n",
      "         macro avg       0.68      0.68      0.68       780\n",
      "      weighted avg       0.68      0.68      0.68       780\n",
      "\n",
      "Name: SGD - F1: 0.6821 - BACC: 0.6821 - ACC: 0.6821 - MCC: 0.6700 - Elapsed: 0.27s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.74      0.83      0.78        30\n",
      "            asmais       0.39      0.23      0.29        30\n",
      "               bbc       0.50      0.30      0.37        30\n",
      "           ciencia       0.65      0.73      0.69        30\n",
      "           colunas       0.56      0.17      0.26        30\n",
      "            comida       0.66      0.77      0.71        30\n",
      "         cotidiano       0.63      0.63      0.63        30\n",
      "          educacao       0.74      0.93      0.82        30\n",
      "empreendedorsocial       0.80      0.80      0.80        30\n",
      "  equilibrioesaude       0.48      0.47      0.47        30\n",
      "           esporte       0.71      0.80      0.75        30\n",
      "          folhinha       0.77      0.77      0.77        30\n",
      "         ilustrada       0.57      0.43      0.49        30\n",
      "      ilustrissima       0.62      0.70      0.66        30\n",
      "           mercado       0.62      0.60      0.61        30\n",
      "             mundo       0.80      0.80      0.80        30\n",
      "           opiniao       0.77      0.80      0.79        30\n",
      "    paineldoleitor       1.00      0.97      0.98        30\n",
      "             poder       0.78      0.83      0.81        30\n",
      "          saopaulo       0.63      0.63      0.63        30\n",
      "   seminariosfolha       0.74      0.83      0.78        30\n",
      "          serafina       0.52      0.73      0.61        30\n",
      "         sobretudo       0.66      0.83      0.74        30\n",
      "               tec       0.74      0.83      0.78        30\n",
      "           turismo       0.83      0.83      0.83        30\n",
      "                tv       0.56      0.47      0.51        30\n",
      "\n",
      "          accuracy                           0.68       780\n",
      "         macro avg       0.67      0.68      0.67       780\n",
      "      weighted avg       0.67      0.68      0.67       780\n",
      "\n",
      "Name: NB - F1: 0.6449 - BACC: 0.6449 - ACC: 0.6449 - MCC: 0.6328 - Elapsed: 0.08s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.69      0.83      0.76        30\n",
      "            asmais       0.00      0.00      0.00        30\n",
      "               bbc       0.53      0.30      0.38        30\n",
      "           ciencia       0.75      0.60      0.67        30\n",
      "           colunas       0.33      0.03      0.06        30\n",
      "            comida       0.71      0.73      0.72        30\n",
      "         cotidiano       0.54      0.70      0.61        30\n",
      "          educacao       0.76      0.93      0.84        30\n",
      "empreendedorsocial       0.75      0.70      0.72        30\n",
      "  equilibrioesaude       0.51      0.87      0.64        30\n",
      "           esporte       0.70      0.87      0.78        30\n",
      "          folhinha       0.78      0.70      0.74        30\n",
      "         ilustrada       0.68      0.50      0.58        30\n",
      "      ilustrissima       0.59      0.53      0.56        30\n",
      "           mercado       0.49      0.60      0.54        30\n",
      "             mundo       0.59      0.80      0.68        30\n",
      "           opiniao       0.67      0.60      0.63        30\n",
      "    paineldoleitor       0.97      0.93      0.95        30\n",
      "             poder       0.64      0.93      0.76        30\n",
      "          saopaulo       0.62      0.67      0.65        30\n",
      "   seminariosfolha       0.68      0.70      0.69        30\n",
      "          serafina       0.40      0.70      0.51        30\n",
      "         sobretudo       0.72      0.87      0.79        30\n",
      "               tec       0.71      0.83      0.77        30\n",
      "           turismo       0.75      0.70      0.72        30\n",
      "                tv       0.67      0.13      0.22        30\n",
      "\n",
      "          accuracy                           0.64       780\n",
      "         macro avg       0.62      0.64      0.61       780\n",
      "      weighted avg       0.62      0.64      0.61       780\n",
      "\n",
      "Name: LSVC - F1: 0.6859 - BACC: 0.6859 - ACC: 0.6859 - MCC: 0.6737 - Elapsed: 0.86s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.77      0.77      0.77        30\n",
      "            asmais       0.36      0.27      0.31        30\n",
      "               bbc       0.45      0.33      0.38        30\n",
      "           ciencia       0.58      0.70      0.64        30\n",
      "           colunas       0.40      0.20      0.27        30\n",
      "            comida       0.71      0.80      0.75        30\n",
      "         cotidiano       0.67      0.67      0.67        30\n",
      "          educacao       0.76      0.93      0.84        30\n",
      "empreendedorsocial       0.85      0.77      0.81        30\n",
      "  equilibrioesaude       0.48      0.50      0.49        30\n",
      "           esporte       0.78      0.83      0.81        30\n",
      "          folhinha       0.76      0.73      0.75        30\n",
      "         ilustrada       0.63      0.63      0.63        30\n",
      "      ilustrissima       0.72      0.77      0.74        30\n",
      "           mercado       0.64      0.60      0.62        30\n",
      "             mundo       0.67      0.80      0.73        30\n",
      "           opiniao       0.81      0.83      0.82        30\n",
      "    paineldoleitor       1.00      0.97      0.98        30\n",
      "             poder       0.77      0.80      0.79        30\n",
      "          saopaulo       0.67      0.60      0.63        30\n",
      "   seminariosfolha       0.74      0.83      0.78        30\n",
      "          serafina       0.61      0.73      0.67        30\n",
      "         sobretudo       0.73      0.80      0.76        30\n",
      "               tec       0.66      0.77      0.71        30\n",
      "           turismo       0.85      0.73      0.79        30\n",
      "                tv       0.52      0.47      0.49        30\n",
      "\n",
      "          accuracy                           0.69       780\n",
      "         macro avg       0.68      0.69      0.68       780\n",
      "      weighted avg       0.68      0.69      0.68       780\n",
      "\n",
      "Name: KNN - F1: 0.1603 - BACC: 0.1603 - ACC: 0.1603 - MCC: 0.2397 - Elapsed: 13.45s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       1.00      0.23      0.38        30\n",
      "            asmais       0.33      0.03      0.06        30\n",
      "               bbc       0.00      0.00      0.00        30\n",
      "           ciencia       0.33      0.03      0.06        30\n",
      "           colunas       0.00      0.00      0.00        30\n",
      "            comida       0.00      0.00      0.00        30\n",
      "         cotidiano       0.00      0.00      0.00        30\n",
      "          educacao       0.88      0.47      0.61        30\n",
      "empreendedorsocial       1.00      0.17      0.29        30\n",
      "  equilibrioesaude       0.69      0.37      0.48        30\n",
      "           esporte       0.50      0.03      0.06        30\n",
      "          folhinha       0.00      0.00      0.00        30\n",
      "         ilustrada       0.04      0.97      0.08        30\n",
      "      ilustrissima       1.00      0.03      0.06        30\n",
      "           mercado       1.00      0.10      0.18        30\n",
      "             mundo       0.50      0.03      0.06        30\n",
      "           opiniao       0.00      0.00      0.00        30\n",
      "    paineldoleitor       1.00      0.87      0.93        30\n",
      "             poder       0.50      0.03      0.06        30\n",
      "          saopaulo       1.00      0.20      0.33        30\n",
      "   seminariosfolha       0.86      0.20      0.32        30\n",
      "          serafina       0.00      0.00      0.00        30\n",
      "         sobretudo       0.00      0.00      0.00        30\n",
      "               tec       1.00      0.33      0.50        30\n",
      "           turismo       1.00      0.07      0.12        30\n",
      "                tv       0.00      0.00      0.00        30\n",
      "\n",
      "          accuracy                           0.16       780\n",
      "         macro avg       0.49      0.16      0.18       780\n",
      "      weighted avg       0.49      0.16      0.18       780\n",
      "\n",
      "Name: DT - F1: 0.4359 - BACC: 0.4359 - ACC: 0.4359 - MCC: 0.4135 - Elapsed: 12.49s\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ambiente       0.48      0.43      0.46        30\n",
      "            asmais       0.06      0.07      0.06        30\n",
      "               bbc       0.33      0.30      0.32        30\n",
      "           ciencia       0.39      0.37      0.38        30\n",
      "           colunas       0.21      0.23      0.22        30\n",
      "            comida       0.67      0.53      0.59        30\n",
      "         cotidiano       0.27      0.30      0.29        30\n",
      "          educacao       0.56      0.63      0.59        30\n",
      "empreendedorsocial       0.86      0.63      0.73        30\n",
      "  equilibrioesaude       0.38      0.33      0.36        30\n",
      "           esporte       0.42      0.47      0.44        30\n",
      "          folhinha       0.55      0.70      0.62        30\n",
      "         ilustrada       0.27      0.27      0.27        30\n",
      "      ilustrissima       0.35      0.27      0.30        30\n",
      "           mercado       0.19      0.20      0.19        30\n",
      "             mundo       0.30      0.30      0.30        30\n",
      "           opiniao       0.72      0.77      0.74        30\n",
      "    paineldoleitor       0.85      0.97      0.91        30\n",
      "             poder       0.38      0.43      0.41        30\n",
      "          saopaulo       0.47      0.57      0.52        30\n",
      "   seminariosfolha       0.67      0.53      0.59        30\n",
      "          serafina       0.26      0.30      0.28        30\n",
      "         sobretudo       0.52      0.50      0.51        30\n",
      "               tec       0.52      0.43      0.47        30\n",
      "           turismo       0.53      0.53      0.53        30\n",
      "                tv       0.27      0.27      0.27        30\n",
      "\n",
      "          accuracy                           0.44       780\n",
      "         macro avg       0.44      0.44      0.44       780\n",
      "      weighted avg       0.44      0.44      0.44       780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results, creports = train_models(X_train, y_train, X_val, y_val, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
