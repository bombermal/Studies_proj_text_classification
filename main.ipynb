{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções customizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"Remove punctuation and numbers from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A string\n",
    "\n",
    "    Returns:\n",
    "        str: string without punctuation and numbers\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "def remove_multiple_blank_spaces(text):\n",
    "    \"\"\"Remove multiple blank spaces from text\n",
    "\n",
    "    Args:\n",
    "        text (str): A string\n",
    "\n",
    "    Returns:\n",
    "        str: string with only one space between words\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carrega dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.42 s, sys: 656 ms, total: 7.07 s\n",
      "Wall time: 7.07 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lula diz que está 'lascado', mas que ainda tem...</td>\n",
       "      <td>Com a possibilidade de uma condenação impedir ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Decidi ser escrava das mulheres que sofrem', ...</td>\n",
       "      <td>Para Oumou Sangaré, cantora e ativista malines...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Três reportagens da Folha ganham Prêmio Petrob...</td>\n",
       "      <td>Três reportagens da Folha foram vencedoras do ...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>poder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/poder/2017/10/192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Filme 'Star Wars: Os Últimos Jedi' ganha trail...</td>\n",
       "      <td>A Disney divulgou na noite desta segunda-feira...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>ilustrada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/ilustrada/2017/10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CBSS inicia acordos com fintechs e quer 30% do...</td>\n",
       "      <td>O CBSS, banco da holding Elopar dos sócios Bra...</td>\n",
       "      <td>2017-09-10</td>\n",
       "      <td>mercado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www1.folha.uol.com.br/mercado/2017/10/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Lula diz que está 'lascado', mas que ainda tem...   \n",
       "1  'Decidi ser escrava das mulheres que sofrem', ...   \n",
       "2  Três reportagens da Folha ganham Prêmio Petrob...   \n",
       "3  Filme 'Star Wars: Os Últimos Jedi' ganha trail...   \n",
       "4  CBSS inicia acordos com fintechs e quer 30% do...   \n",
       "\n",
       "                                                text        date   category  \\\n",
       "0  Com a possibilidade de uma condenação impedir ...  2017-09-10      poder   \n",
       "1  Para Oumou Sangaré, cantora e ativista malines...  2017-09-10  ilustrada   \n",
       "2  Três reportagens da Folha foram vencedoras do ...  2017-09-10      poder   \n",
       "3  A Disney divulgou na noite desta segunda-feira...  2017-09-10  ilustrada   \n",
       "4  O CBSS, banco da holding Elopar dos sócios Bra...  2017-09-10    mercado   \n",
       "\n",
       "  subcategory                                               link  \n",
       "0         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "1         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "2         NaN  http://www1.folha.uol.com.br/poder/2017/10/192...  \n",
       "3         NaN  http://www1.folha.uol.com.br/ilustrada/2017/10...  \n",
       "4         NaN  http://www1.folha.uol.com.br/mercado/2017/10/1...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Load data\n",
    "data = pd.read_csv(\"Input/archive.zip\", low_memory=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46 ms, sys: 0 ns, total: 46 ms\n",
      "Wall time: 44.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "title               0\n",
       "text              765\n",
       "date                0\n",
       "category            0\n",
       "subcategory    137418\n",
       "link                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Count empty values by columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.8 ms, sys: 3.96 ms, total: 55.7 ms\n",
      "Wall time: 53.7 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>poder</th>\n",
       "      <td>22022</td>\n",
       "      <td>22022</td>\n",
       "      <td>22022</td>\n",
       "      <td>939</td>\n",
       "      <td>22022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colunas</th>\n",
       "      <td>21622</td>\n",
       "      <td>21619</td>\n",
       "      <td>21622</td>\n",
       "      <td>21622</td>\n",
       "      <td>21622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercado</th>\n",
       "      <td>20970</td>\n",
       "      <td>20970</td>\n",
       "      <td>20970</td>\n",
       "      <td>0</td>\n",
       "      <td>20970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esporte</th>\n",
       "      <td>19730</td>\n",
       "      <td>19730</td>\n",
       "      <td>19730</td>\n",
       "      <td>2859</td>\n",
       "      <td>19730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mundo</th>\n",
       "      <td>17130</td>\n",
       "      <td>17130</td>\n",
       "      <td>17130</td>\n",
       "      <td>0</td>\n",
       "      <td>17130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cotidiano</th>\n",
       "      <td>16967</td>\n",
       "      <td>16967</td>\n",
       "      <td>16967</td>\n",
       "      <td>35</td>\n",
       "      <td>16967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrada</th>\n",
       "      <td>16345</td>\n",
       "      <td>15617</td>\n",
       "      <td>16345</td>\n",
       "      <td>0</td>\n",
       "      <td>16345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opiniao</th>\n",
       "      <td>4525</td>\n",
       "      <td>4525</td>\n",
       "      <td>4525</td>\n",
       "      <td>0</td>\n",
       "      <td>4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paineldoleitor</th>\n",
       "      <td>4011</td>\n",
       "      <td>4011</td>\n",
       "      <td>4011</td>\n",
       "      <td>260</td>\n",
       "      <td>4011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saopaulo</th>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>3955</td>\n",
       "      <td>471</td>\n",
       "      <td>3955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tec</th>\n",
       "      <td>2260</td>\n",
       "      <td>2260</td>\n",
       "      <td>2260</td>\n",
       "      <td>0</td>\n",
       "      <td>2260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tv</th>\n",
       "      <td>2142</td>\n",
       "      <td>2123</td>\n",
       "      <td>2142</td>\n",
       "      <td>2142</td>\n",
       "      <td>2142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educacao</th>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "      <td>2118</td>\n",
       "      <td>0</td>\n",
       "      <td>2118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turismo</th>\n",
       "      <td>1903</td>\n",
       "      <td>1903</td>\n",
       "      <td>1903</td>\n",
       "      <td>0</td>\n",
       "      <td>1903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ilustrissima</th>\n",
       "      <td>1411</td>\n",
       "      <td>1409</td>\n",
       "      <td>1411</td>\n",
       "      <td>0</td>\n",
       "      <td>1411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ciencia</th>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>1335</td>\n",
       "      <td>0</td>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equilibrioesaude</th>\n",
       "      <td>1312</td>\n",
       "      <td>1312</td>\n",
       "      <td>1312</td>\n",
       "      <td>0</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sobretudo</th>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc</th>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>folhinha</th>\n",
       "      <td>876</td>\n",
       "      <td>875</td>\n",
       "      <td>876</td>\n",
       "      <td>0</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empreendedorsocial</th>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>841</td>\n",
       "      <td>150</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comida</th>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>asmais</th>\n",
       "      <td>548</td>\n",
       "      <td>547</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambiente</th>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seminariosfolha</th>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serafina</th>\n",
       "      <td>334</td>\n",
       "      <td>331</td>\n",
       "      <td>334</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o-melhor-de-sao-paulo</th>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>71</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vice</th>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guia-de-livros-discos-filmes</th>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>topofmind</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banco-de-dados</th>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dw</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>especial</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infograficos</th>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cenarios-2017</th>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfi</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guia-de-livros-filmes-discos</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multimidia</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treinamento</th>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>treinamentocienciaesaude</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mulher</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euronews</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ombudsman</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contas-de-casa</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bichos</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>musica</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title   text   date  subcategory   link\n",
       "category                                                             \n",
       "poder                         22022  22022  22022          939  22022\n",
       "colunas                       21622  21619  21622        21622  21622\n",
       "mercado                       20970  20970  20970            0  20970\n",
       "esporte                       19730  19730  19730         2859  19730\n",
       "mundo                         17130  17130  17130            0  17130\n",
       "cotidiano                     16967  16967  16967           35  16967\n",
       "ilustrada                     16345  15617  16345            0  16345\n",
       "opiniao                        4525   4525   4525            0   4525\n",
       "paineldoleitor                 4011   4011   4011          260   4011\n",
       "saopaulo                       3955   3955   3955          471   3955\n",
       "tec                            2260   2260   2260            0   2260\n",
       "tv                             2142   2123   2142         2142   2142\n",
       "educacao                       2118   2118   2118            0   2118\n",
       "turismo                        1903   1903   1903            0   1903\n",
       "ilustrissima                   1411   1409   1411            0   1411\n",
       "ciencia                        1335   1335   1335            0   1335\n",
       "equilibrioesaude               1312   1312   1312            0   1312\n",
       "sobretudo                      1057   1057   1057         1057   1057\n",
       "bbc                             980    980    980            0    980\n",
       "folhinha                        876    875    876            0    876\n",
       "empreendedorsocial              841    841    841          150    841\n",
       "comida                          828    828    828            0    828\n",
       "asmais                          548    547    548            0    548\n",
       "ambiente                        491    491    491            0    491\n",
       "seminariosfolha                 379    379    379            0    379\n",
       "serafina                        334    331    334            0    334\n",
       "o-melhor-de-sao-paulo           189    189    189           71    189\n",
       "vice                            146    146    146            0    146\n",
       "guia-de-livros-discos-filmes    143    143    143            0    143\n",
       "topofmind                        86     86     86            0     86\n",
       "banco-de-dados                   64     64     64            0     64\n",
       "dw                               48     48     48            0     48\n",
       "especial                         43     43     43            0     43\n",
       "infograficos                     43     40     43            0     43\n",
       "cenarios-2017                    43     43     43            0     43\n",
       "rfi                              29     29     29            0     29\n",
       "guia-de-livros-filmes-discos     28     28     28            0     28\n",
       "multimidia                       27     27     27           27     27\n",
       "treinamento                      21     21     21            0     21\n",
       "treinamentocienciaesaude         18     18     18            0     18\n",
       "mulher                           16     16     16            0     16\n",
       "euronews                          8      8      8            0      8\n",
       "ombudsman                         3      3      3            0      3\n",
       "contas-de-casa                    2      0      2            2      2\n",
       "2016                              1      0      1            0      1\n",
       "bichos                            1      1      1            0      1\n",
       "musica                            1      0      1            0      1\n",
       "2015                              1      0      1            0      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Count items by category\n",
    "data.groupby(\"category\").count().sort_values(by=\"title\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 167053 entries, 0 to 166970\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   title        167053 non-null  object\n",
      " 1   text         166288 non-null  object\n",
      " 2   date         167053 non-null  object\n",
      " 3   category     167053 non-null  object\n",
      " 4   subcategory  29635 non-null   object\n",
      " 5   link         167053 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 8.9+ MB\n",
      "CPU times: user 99.7 ms, sys: 12.7 ms, total: 112 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# To avoid unbalanced data, we will remove the categories with less than 1500 items\n",
    "categories_mask = data[\"category\"].value_counts() > 1500\n",
    "categories_mask = categories_mask[categories_mask.values].index\n",
    "# Filter data\n",
    "mask = data[\"category\"].isin(categories_mask)\n",
    "data_filtered = data[mask]\n",
    "temp_df = data.loc[~mask]\n",
    "temp_df[\"category\"] = \"outros\"\n",
    "\n",
    "data_filtered = pd.concat([data_filtered, temp_df])\n",
    "data_filtered.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 137 ms, sys: 14.6 ms, total: 151 ms\n",
      "Wall time: 148 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "colunas           1500\n",
       "cotidiano         1500\n",
       "educacao          1500\n",
       "esporte           1500\n",
       "ilustrada         1500\n",
       "mercado           1500\n",
       "mundo             1500\n",
       "opiniao           1500\n",
       "outros            1500\n",
       "paineldoleitor    1500\n",
       "poder             1500\n",
       "saopaulo          1500\n",
       "tec               1500\n",
       "turismo           1500\n",
       "tv                1500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "seed = 333\n",
    "data_balanced = data_filtered.copy().groupby('category').apply(lambda x: x.sample(1500, random_state=seed))\n",
    "\n",
    "# Store the unused data for future use\n",
    "# balanced_index = set(data_balanced.unstack(level=0).index)\n",
    "# balanced_categories = data_balanced.category.unique()\n",
    "# mask = ~(data_filtered.index.isin(balanced_index)) & (data_filtered.category.isin(balanced_categories))\n",
    "# data_unbalanced = data_filtered[mask].reset_index(drop=True)\n",
    "\n",
    "# Balanced data\n",
    "data_balanced.reset_index(drop=True, inplace=True)\n",
    "data_balanced.category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.3 s, sys: 78.8 ms, total: 16.4 s\n",
      "Wall time: 16.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>norm_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zuckerberg ataca isolacionismo e promete sufoc...</td>\n",
       "      <td>zuckerberg ataca isolacionismo e promete sufoc...</td>\n",
       "      <td>colunas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017 será sonho ou pesadelo para Temer? BRASÍL...</td>\n",
       "      <td>sera sonho ou pesadelo para temer brasilia dep...</td>\n",
       "      <td>colunas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aviso Excepcionalmente nesta quarta (8) a colu...</td>\n",
       "      <td>aviso excepcionalmente nesta quarta a coluna n...</td>\n",
       "      <td>colunas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Visitar hortas virou passeio Estou em Campos d...</td>\n",
       "      <td>visitar hortas virou passeio estou em campos d...</td>\n",
       "      <td>colunas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O fiu-fiu de um macho não opressor Sou a favor...</td>\n",
       "      <td>o fiu fiu de um macho nao opressor sou a favor...</td>\n",
       "      <td>colunas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  \\\n",
       "0  Zuckerberg ataca isolacionismo e promete sufoc...   \n",
       "1  2017 será sonho ou pesadelo para Temer? BRASÍL...   \n",
       "2  Aviso Excepcionalmente nesta quarta (8) a colu...   \n",
       "3  Visitar hortas virou passeio Estou em Campos d...   \n",
       "4  O fiu-fiu de um macho não opressor Sou a favor...   \n",
       "\n",
       "                                           norm_text category  \n",
       "0  zuckerberg ataca isolacionismo e promete sufoc...  colunas  \n",
       "1  sera sonho ou pesadelo para temer brasilia dep...  colunas  \n",
       "2  aviso excepcionalmente nesta quarta a coluna n...  colunas  \n",
       "3  visitar hortas virou passeio estou em campos d...  colunas  \n",
       "4  o fiu fiu de um macho nao opressor sou a favor...  colunas  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Combining text and title\n",
    "df_balanced = data_balanced[[\"title\", \"text\", \"category\"]].copy()\n",
    "df_balanced[\"full_text\"] = df_balanced[\"title\"] + \" \" + df_balanced[\"text\"]\n",
    "# Text cleaning\n",
    "df_balanced[\"norm_text\"] = df_balanced.full_text.apply(lambda x: remove_multiple_blank_spaces(\n",
    "                                                remove_punctuation(\n",
    "                                                    unidecode(str(x).lower())\n",
    "                                                )\n",
    "                                            ).strip())\n",
    "df_balanced = df_balanced[[\"full_text\", \"norm_text\", \"category\"]]\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 ms, sys: 3.91 ms, total: 6.6 ms\n",
      "Wall time: 5.53 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Change category to numeric\n",
    "df_balanced[\"category\"] = df_balanced.category.astype(\"category\")\n",
    "category_map = {key: value for key, value in zip(df_balanced.category, df_balanced.category.cat.codes)}\n",
    "df_balanced.category = df_balanced.category.cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.8 ms, sys: 3.98 ms, total: 15.7 ms\n",
      "Wall time: 14.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((18000, 3), (2250, 3), (2250, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_balanced, test_size=0.2, random_state=seed, stratify=df_balanced.category)\n",
    "df_test, df_val = train_test_split(df_test, test_size=0.5, random_state=seed, stratify=df_test.category)\n",
    "\n",
    "df_train.shape, df_test.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words and vectorization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python3 -m spacy download pt_core_news_sm\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.1 s, sys: 1.66 s, total: 36.8 s\n",
      "Wall time: 36.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 3),\n",
       "                stop_words=[&#x27;mesmo&#x27;, &#x27;povo&#x27;, &#x27;custa&#x27;, &#x27;poder&#x27;, &#x27;elas&#x27;, &#x27;ai&#x27;,\n",
       "                            &#x27;grupo&#x27;, &#x27;dao&#x27;, &#x27;quais&#x27;, &#x27;podera&#x27;, &#x27;dez&#x27;, &#x27;foste&#x27;,\n",
       "                            &#x27;hajam&#x27;, &#x27;proxima&#x27;, &#x27;segunda&#x27;, &#x27;tao&#x27;, &#x27;vezes&#x27;,\n",
       "                            &#x27;tiveste&#x27;, &#x27;obrigada&#x27;, &#x27;apontar&#x27;, &#x27;tres&#x27;, &#x27;dos&#x27;,\n",
       "                            &#x27;hajamos&#x27;, &#x27;fim&#x27;, &#x27;nenhuma&#x27;, &#x27;pode&#x27;, &#x27;favor&#x27;, &#x27;mal&#x27;,\n",
       "                            &#x27;pelas&#x27;, &#x27;sobre&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 3),\n",
       "                stop_words=[&#x27;mesmo&#x27;, &#x27;povo&#x27;, &#x27;custa&#x27;, &#x27;poder&#x27;, &#x27;elas&#x27;, &#x27;ai&#x27;,\n",
       "                            &#x27;grupo&#x27;, &#x27;dao&#x27;, &#x27;quais&#x27;, &#x27;podera&#x27;, &#x27;dez&#x27;, &#x27;foste&#x27;,\n",
       "                            &#x27;hajam&#x27;, &#x27;proxima&#x27;, &#x27;segunda&#x27;, &#x27;tao&#x27;, &#x27;vezes&#x27;,\n",
       "                            &#x27;tiveste&#x27;, &#x27;obrigada&#x27;, &#x27;apontar&#x27;, &#x27;tres&#x27;, &#x27;dos&#x27;,\n",
       "                            &#x27;hajamos&#x27;, &#x27;fim&#x27;, &#x27;nenhuma&#x27;, &#x27;pode&#x27;, &#x27;favor&#x27;, &#x27;mal&#x27;,\n",
       "                            &#x27;pelas&#x27;, &#x27;sobre&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_df=0.8, max_features=2000, min_df=5, ngram_range=(1, 3),\n",
       "                stop_words=['mesmo', 'povo', 'custa', 'poder', 'elas', 'ai',\n",
       "                            'grupo', 'dao', 'quais', 'podera', 'dez', 'foste',\n",
       "                            'hajam', 'proxima', 'segunda', 'tao', 'vezes',\n",
       "                            'tiveste', 'obrigada', 'apontar', 'tres', 'dos',\n",
       "                            'hajamos', 'fim', 'nenhuma', 'pode', 'favor', 'mal',\n",
       "                            'pelas', 'sobre', ...])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Stopwords\n",
    "stopwords_nltk = stopwords.words('portuguese')\n",
    "stopwords_spacy = spacy.load('pt_core_news_sm').Defaults.stop_words\n",
    "both_stopwords = set(stopwords_nltk) | set(stopwords_spacy)\n",
    "both_stopwords = list(map(unidecode, both_stopwords))\n",
    "\n",
    "# Create a tfidf vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=both_stopwords, max_features=2000,\n",
    "                             ngram_range=(1, 3), min_df=5, max_df=0.8, lowercase=True)\n",
    "\n",
    "# Fit the vectorizer with our texts\n",
    "vectorizer.fit(df_train.norm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 3.78 ms, total: 10.3 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Transform our texts into vectors\n",
    "X_train = vectorizer.transform(df_train.norm_text)\n",
    "X_val = vectorizer.transform(df_val.norm_text)\n",
    "X_test = vectorizer.transform(df_test.norm_text)\n",
    "\n",
    "y_train = df_train.category\n",
    "y_val = df_val.category\n",
    "y_test = df_test.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1 µs, total: 11 µs\n",
      "Wall time: 15.3 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((18000, 2000), (2250, 2000), (2250, 2000))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.1 ms, sys: 56 µs, total: 17.2 ms\n",
      "Wall time: 15.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['seg sex - estac - pensao - regiao oeste tel - debate problemas brasileiros - mundiais refletir - mundiais refletir diversas - publicados assinatura - publicados assinatura traduzem - publicacao obedece proposito',\n",
       " 'publicacao obedece - refletir diversas - brasileiros mundiais refletir - brasileiros mundiais - assinatura traduzem - br artigos publicados - assinatura traduzem opiniao - artigos publicados assinatura - jornal publicacao - obedece proposito',\n",
       " 'obedece proposito estimular - jornal publicacao obedece - estimular debate problemas - refletir diversas tendencias - proposito estimular debate - opiniao jornal publicacao - br artigos - problemas brasileiros mundiais - diversas tendencias - traduzem opiniao jornal']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Sum all the columns\n",
    "X_train_sum = np.sum(X_train, axis=0)\n",
    "\n",
    "# Sort the sum of columns\n",
    "sorted_ngrams = np.asarray(np.argsort(X_train_sum)[::-1]).reshape(-1)\n",
    "\n",
    "# Get the top 10 ngrams\n",
    "top_ngrams = sorted_ngrams[:30]\n",
    "\n",
    "# Get the names of the top 10 ngrams\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "# reshape a list into a list of lists with 3 \"rows\"\n",
    "[ \" - \".join(ii) for ii in np.array_split(feature_names[top_ngrams], 3) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             balanced_accuracy_score, classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (accuracy_score, balanced_accuracy_score,\n",
    "                             classification_report, confusion_matrix, f1_score,\n",
    "                             matthews_corrcoef)\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import (f1_score, balanced_accuracy_score, accuracy_score,\n",
    "                             classification_report, matthews_corrcoef,\n",
    "                             confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_valid, y_valid, n_jobs=-1):\n",
    "    \n",
    "    # Spot Check Algorithms\n",
    "    models = []\n",
    "    models.append(('Calibrated-LSVC', CalibratedClassifierCV(LinearSVC(random_state=seed, class_weight='balanced'))))\n",
    "    models.append(('LR', LogisticRegression(random_state=seed, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('RF', RandomForestClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('LGBM', LGBMClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('XGB', XGBClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('MLP', MLPClassifier(random_state=seed)))\n",
    "    models.append(('SGD', SGDClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')))\n",
    "    models.append(('NB', MultinomialNB()))\n",
    "    models.append(('LSVC', LinearSVC(random_state=seed, class_weight='balanced')))\n",
    "    models.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "    models.append(('DT', DecisionTreeClassifier(random_state=seed, class_weight='balanced')))\n",
    "    \n",
    "    results = []\n",
    "    creports = []\n",
    "    \n",
    "    for name, model in models:\n",
    "        start_time = time.time()\n",
    "\n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "            pred = model.predict(X_valid)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error {name} - {e}')\n",
    "            continue \n",
    "\n",
    "        f1 = f1_score(y_valid, pred, average='micro')\n",
    "        bacc = balanced_accuracy_score(y_valid, pred)\n",
    "        acc = accuracy_score(y_valid, pred)\n",
    "        cr = classification_report(y_valid, pred)\n",
    "        mcc = matthews_corrcoef(y_valid, pred)\n",
    "        cm = confusion_matrix(y_valid, pred)\n",
    "        creports.append([name, cr, cm])\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "        results.append([name, f1, bacc, acc, mcc, elapsed, cm, cr])\n",
    "\n",
    "        msg = f'Name: {name} - F1: {f1:.4f} - BACC: {bacc:.4f} - ACC: {acc:.4f} - MCC: {mcc:.4f} - Elapsed: {elapsed:.2f}s'\n",
    "        print(msg)\n",
    "        # print(cr)\n",
    "        # print(cm)\n",
    "        # print('*' * 20, '\\n')\n",
    "\n",
    "    columns = ['Model', 'F1', 'BACC', 'ACC', 'MCC', 'Total Time', 'Confusion Matrix', 'Classification Report']\n",
    "    df_results = pd.DataFrame(results, columns=columns)\n",
    "    df_results['Confusion Matrix'] = df_results['Confusion Matrix'].apply(lambda x: str(x))\n",
    "\n",
    "    return df_results, creports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Calibrated-LSVC - F1: 0.7804 - BACC: 0.7804 - ACC: 0.7804 - MCC: 0.7649 - Elapsed: 5.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: LR - F1: 0.7813 - BACC: 0.7813 - ACC: 0.7813 - MCC: 0.7659 - Elapsed: 4.83s\n",
      "Name: RF - F1: 0.7524 - BACC: 0.7524 - ACC: 0.7524 - MCC: 0.7361 - Elapsed: 8.34s\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.294687 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 368841\n",
      "[LightGBM] [Info] Number of data points in the train set: 18000, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Name: LGBM - F1: 0.8013 - BACC: 0.8013 - ACC: 0.8013 - MCC: 0.7873 - Elapsed: 115.55s\n",
      "[02:12:48] WARNING: ../src/learner.cc:767: \n",
      "Parameters: { \"class_weight\" } are not used.\n",
      "\n",
      "Name: XGB - F1: 0.7911 - BACC: 0.7911 - ACC: 0.7911 - MCC: 0.7764 - Elapsed: 154.13s\n",
      "Name: MLP - F1: 0.7391 - BACC: 0.7391 - ACC: 0.7391 - MCC: 0.7207 - Elapsed: 78.46s\n",
      "Name: SGD - F1: 0.7809 - BACC: 0.7809 - ACC: 0.7809 - MCC: 0.7661 - Elapsed: 0.25s\n",
      "Name: NB - F1: 0.7129 - BACC: 0.7129 - ACC: 0.7129 - MCC: 0.6943 - Elapsed: 0.04s\n",
      "Name: LSVC - F1: 0.7813 - BACC: 0.7813 - ACC: 0.7813 - MCC: 0.7659 - Elapsed: 1.28s\n",
      "Name: KNN - F1: 0.3116 - BACC: 0.3116 - ACC: 0.3116 - MCC: 0.3649 - Elapsed: 43.65s\n",
      "Name: DT - F1: 0.5924 - BACC: 0.5924 - ACC: 0.5924 - MCC: 0.5635 - Elapsed: 12.46s\n",
      "CPU times: user 45min 49s, sys: 6min 32s, total: 52min 21s\n",
      "Wall time: 7min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_results, creports = train_models(X_train, y_train, X_val, y_val, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>F1</th>\n",
       "      <th>BACC</th>\n",
       "      <th>ACC</th>\n",
       "      <th>MCC</th>\n",
       "      <th>Total Time</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Classification Report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.801333</td>\n",
       "      <td>0.801333</td>\n",
       "      <td>0.801333</td>\n",
       "      <td>0.787323</td>\n",
       "      <td>115.546797</td>\n",
       "      <td>[[ 85   8   2   7   6   8   3   0  15   1   8 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.776352</td>\n",
       "      <td>154.129872</td>\n",
       "      <td>[[ 77   8   2   6   6   9   5   0  13   0   8 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.765912</td>\n",
       "      <td>4.826545</td>\n",
       "      <td>[[ 68   7   1   6  12  12   6   1  16   0  12 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LSVC</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.781333</td>\n",
       "      <td>0.765860</td>\n",
       "      <td>1.275591</td>\n",
       "      <td>[[ 78   4   2   3  12  12   8   1  10   0   8 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.780889</td>\n",
       "      <td>0.780889</td>\n",
       "      <td>0.780889</td>\n",
       "      <td>0.766061</td>\n",
       "      <td>0.249234</td>\n",
       "      <td>[[ 61   7   4   9  15  14   6   2   9   0  11 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Calibrated-LSVC</td>\n",
       "      <td>0.780444</td>\n",
       "      <td>0.780444</td>\n",
       "      <td>0.780444</td>\n",
       "      <td>0.764929</td>\n",
       "      <td>5.378097</td>\n",
       "      <td>[[ 77   5   1   3  12  12   7   1  11   0  10 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.752444</td>\n",
       "      <td>0.752444</td>\n",
       "      <td>0.752444</td>\n",
       "      <td>0.736140</td>\n",
       "      <td>8.337250</td>\n",
       "      <td>[[ 45  10   5  10  13  11  10   0  10   0  20 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.739111</td>\n",
       "      <td>0.739111</td>\n",
       "      <td>0.739111</td>\n",
       "      <td>0.720683</td>\n",
       "      <td>78.456497</td>\n",
       "      <td>[[ 87   6   1   1  10   6   4   1  21   0   5 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NB</td>\n",
       "      <td>0.712889</td>\n",
       "      <td>0.712889</td>\n",
       "      <td>0.712889</td>\n",
       "      <td>0.694303</td>\n",
       "      <td>0.037134</td>\n",
       "      <td>[[ 29   7   2  10  16  20   8   4  23   0  23 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.592444</td>\n",
       "      <td>0.563505</td>\n",
       "      <td>12.456806</td>\n",
       "      <td>[[ 38  12   5  10  15  14   9   0   9   4  10 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.311556</td>\n",
       "      <td>0.311556</td>\n",
       "      <td>0.311556</td>\n",
       "      <td>0.364939</td>\n",
       "      <td>43.650285</td>\n",
       "      <td>[[  4   0   0   0 136   2   2   0   1   0   4 ...</td>\n",
       "      <td>precision    recall  f1-score   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model        F1      BACC       ACC       MCC  Total Time  \\\n",
       "3              LGBM  0.801333  0.801333  0.801333  0.787323  115.546797   \n",
       "4               XGB  0.791111  0.791111  0.791111  0.776352  154.129872   \n",
       "1                LR  0.781333  0.781333  0.781333  0.765912    4.826545   \n",
       "8              LSVC  0.781333  0.781333  0.781333  0.765860    1.275591   \n",
       "6               SGD  0.780889  0.780889  0.780889  0.766061    0.249234   \n",
       "0   Calibrated-LSVC  0.780444  0.780444  0.780444  0.764929    5.378097   \n",
       "2                RF  0.752444  0.752444  0.752444  0.736140    8.337250   \n",
       "5               MLP  0.739111  0.739111  0.739111  0.720683   78.456497   \n",
       "7                NB  0.712889  0.712889  0.712889  0.694303    0.037134   \n",
       "10               DT  0.592444  0.592444  0.592444  0.563505   12.456806   \n",
       "9               KNN  0.311556  0.311556  0.311556  0.364939   43.650285   \n",
       "\n",
       "                                     Confusion Matrix  \\\n",
       "3   [[ 85   8   2   7   6   8   3   0  15   1   8 ...   \n",
       "4   [[ 77   8   2   6   6   9   5   0  13   0   8 ...   \n",
       "1   [[ 68   7   1   6  12  12   6   1  16   0  12 ...   \n",
       "8   [[ 78   4   2   3  12  12   8   1  10   0   8 ...   \n",
       "6   [[ 61   7   4   9  15  14   6   2   9   0  11 ...   \n",
       "0   [[ 77   5   1   3  12  12   7   1  11   0  10 ...   \n",
       "2   [[ 45  10   5  10  13  11  10   0  10   0  20 ...   \n",
       "5   [[ 87   6   1   1  10   6   4   1  21   0   5 ...   \n",
       "7   [[ 29   7   2  10  16  20   8   4  23   0  23 ...   \n",
       "10  [[ 38  12   5  10  15  14   9   0   9   4  10 ...   \n",
       "9   [[  4   0   0   0 136   2   2   0   1   0   4 ...   \n",
       "\n",
       "                                Classification Report  \n",
       "3                 precision    recall  f1-score   ...  \n",
       "4                 precision    recall  f1-score   ...  \n",
       "1                 precision    recall  f1-score   ...  \n",
       "8                 precision    recall  f1-score   ...  \n",
       "6                 precision    recall  f1-score   ...  \n",
       "0                 precision    recall  f1-score   ...  \n",
       "2                 precision    recall  f1-score   ...  \n",
       "5                 precision    recall  f1-score   ...  \n",
       "7                 precision    recall  f1-score   ...  \n",
       "10                precision    recall  f1-score   ...  \n",
       "9                 precision    recall  f1-score   ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(by='F1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Classifier Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.084311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 368841\n",
      "[LightGBM] [Info] Number of data points in the train set: 18000, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.416844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.424203 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 321369\n",
      "[LightGBM] [Info] Total Bins 321399\n",
      "[LightGBM] [Info] Number of data points in the train set: 14400, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Number of data points in the train set: 14400, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.303272 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 322070\n",
      "[LightGBM] [Info] Number of data points in the train set: 14400, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.346020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 321203\n",
      "[LightGBM] [Info] Number of data points in the train set: 14400, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.351851 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 321148\n",
      "[LightGBM] [Info] Number of data points in the train set: 14400, number of used features: 2000\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Info] Start training from score -2.708050\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8187 - BACC: 0.8187 - ACC: 0.8187 - MCC: 0.8058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66       150\n",
      "           1       0.78      0.75      0.77       150\n",
      "           2       0.93      0.95      0.94       150\n",
      "           3       0.92      0.95      0.93       150\n",
      "           4       0.70      0.81      0.75       150\n",
      "           5       0.80      0.71      0.75       150\n",
      "           6       0.85      0.85      0.85       150\n",
      "           7       0.99      0.96      0.97       150\n",
      "           8       0.49      0.49      0.49       150\n",
      "           9       0.99      0.96      0.97       150\n",
      "          10       0.78      0.82      0.80       150\n",
      "          11       0.81      0.84      0.83       150\n",
      "          12       0.86      0.87      0.86       150\n",
      "          13       0.87      0.83      0.85       150\n",
      "          14       0.87      0.83      0.85       150\n",
      "\n",
      "    accuracy                           0.82      2250\n",
      "   macro avg       0.82      0.82      0.82      2250\n",
      "weighted avg       0.82      0.82      0.82      2250\n",
      "\n",
      "[[100   5   1   1   8   4   3   1  14   0   6   4   0   2   1]\n",
      " [  3 113   3   1   4   2   1   0  11   0   7   1   0   0   4]\n",
      " [  0   3 143   0   0   0   0   0   4   0   0   0   0   0   0]\n",
      " [  2   2   0 142   0   0   2   0   0   0   1   0   0   0   1]\n",
      " [  5   1   0   0 122   1   2   0   9   1   1   4   1   1   2]\n",
      " [  5   1   2   0   2 106   3   0   8   0  10   2  10   1   0]\n",
      " [  1   3   0   0   2   1 128   0   7   0   1   0   0   5   2]\n",
      " [  5   0   0   0   0   0   0 144   0   0   1   0   0   0   0]\n",
      " [ 13   4   3   4  12   2   5   0  73   0   5  10   7   7   5]\n",
      " [  1   0   0   0   2   0   0   0   2 144   1   0   0   0   0]\n",
      " [  6   4   0   0   1   9   2   1   1   1 123   0   1   0   1]\n",
      " [  2   4   1   0   9   0   0   0   7   0   0 126   0   1   0]\n",
      " [  5   2   0   1   2   4   1   0   5   0   0   0 130   0   0]\n",
      " [  2   2   0   1   2   2   1   0   5   0   0   7   2 124   2]\n",
      " [  1   1   1   4   9   1   2   0   3   0   2   1   0   1 124]]\n"
     ]
    }
   ],
   "source": [
    "model_lr = LogisticRegression(random_state=seed, n_jobs=-1, class_weight='balanced'))\n",
    "model_calibrated_lsvc = CalibratedClassifierCV(LinearSVC(random_state=seed, class_weight='balanced'))\n",
    "model_lgbm = LGBMClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "estimators = [\n",
    "                ('lr', model_lr),\n",
    "                ('calibrated_lsvc', model_calibrated_lsvc),\n",
    "                ('lgbm', model_lgbm)\n",
    "            ]\n",
    "\n",
    "model_stacked = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=seed, n_jobs=-1, class_weight='balanced'), n_jobs=2, cv=5)\n",
    "\n",
    "model_stacked.fit(X_train, y_train)\n",
    "\n",
    "pred = model_stacked.predict(X_val)\n",
    "\n",
    "f1 = f1_score(y_val, pred, average='micro')\n",
    "bacc = balanced_accuracy_score(y_val, pred)\n",
    "acc = accuracy_score(y_val, pred)\n",
    "cr = classification_report(y_val, pred)\n",
    "mcc = matthews_corrcoef(y_val, pred)\n",
    "cm = confusion_matrix(y_val, pred)\n",
    "\n",
    "print(f'F1: {f1:.4f} - BACC: {bacc:.4f} - ACC: {acc:.4f} - MCC: {mcc:.4f}')\n",
    "print(cr)\n",
    "print(cm)\n",
    "\n",
    "# Took 1.5 minute to run in a 48 core CPU\n",
    "\n",
    "# 11 min xeon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Best score:  0.7616581042380561\n",
      "Valid MCC:  0.7808888888888889\n"
     ]
    }
   ],
   "source": [
    "# Performing grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter grid for the search\n",
    "param_grid = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object with the SGDClassifier and parameter grid\n",
    "grid_search = GridSearchCV(model_sgd, param_grid, cv=3, scoring=scorer_mcc, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search by fitting training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MCC score found by the grid search\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model with chosen parameters on the test set\n",
    "best_estimator = grid_search.best_estimator_\n",
    "valid_mcc = best_estimator.score(X_val, y_val)\n",
    "print(\"Valid MCC: \", valid_mcc)\n",
    "\n",
    "# Took 65 minutes to run in a 48 core CPU\n",
    "# it performs 4 * 5 * 5 * 3 combinations of parameters, which is 300 combinations in total. Since it uses Cross Validation with 3 folds, it will train 900 models in total!!!!!\n",
    "\n",
    "# Best parameters:  {'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l1'}\n",
    "# Best score:  0.8971782029568908\n",
    "# Valid MCC:  0.9570773263433814\n",
    "\n",
    "# 49 min xeon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/home/ivan/.local/lib/python3.10/site-packages/sklearn/linear_model/_stochastic_gradient.py:713: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'penalty': 'l2', 'max_iter': 1000, 'loss': 'hinge', 'alpha': 0.0001}\n",
      "Best score:  0.7616581042380561\n",
      "Valid MCC:  0.7808888888888889\n"
     ]
    }
   ],
   "source": [
    "# Performing Random Search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter grid for the search\n",
    "param_dist = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "\n",
    "# Create the RandomizedSearchCV object with the SGDClassifier and parameter distribution\n",
    "random_search = RandomizedSearchCV(model_sgd, param_dist, cv=3, scoring=scorer_mcc, \n",
    "                                   n_jobs=-1, n_iter=60, random_state=seed)\n",
    "\n",
    "# Perform the random search by fitting training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MCC score found by the random search\n",
    "print(\"Best parameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)\n",
    "\n",
    "# Evaluate the model with chosen parameters on the test set\n",
    "best_estimator = random_search.best_estimator_\n",
    "valid_mcc = best_estimator.score(X_val, y_val)\n",
    "print(\"Valid MCC: \", valid_mcc)\n",
    "\n",
    "# This will typically run faster than GridSearchCV due to the reduced number of parameter combinations.\n",
    "# Time to run: 26 minutes in a 48 core CPU\n",
    "# Best parameters:  {'penalty': 'elasticnet', 'max_iter': 2000, 'loss': 'modified_huber', 'alpha': 0.0001}\n",
    "# Best score:  0.9068535026549907\n",
    "# Valid MCC:  0.963302752293578\n",
    "\n",
    "# 18 min xeon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Performing Bayesian Optimization for Hyperparameter Tuning\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskopt\u001b[39;00m \u001b[39mimport\u001b[39;00m BayesSearchCV\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m make_scorer\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinear_model\u001b[39;00m \u001b[39mimport\u001b[39;00m SGDClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skopt'"
     ]
    }
   ],
   "source": [
    "# Performing Bayesian Optimization for Hyperparameter Tuning\n",
    "import numpy as np\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "scorer_mcc = make_scorer(matthews_corrcoef)\n",
    "\n",
    "model_sgd = SGDClassifier(random_state=seed, n_jobs=-1, class_weight='balanced')\n",
    "\n",
    "# Define parameter search space for the optimizer\n",
    "param_space = {\n",
    "    'loss': ['hinge', 'log_loss', 'squared_hinge', 'modified_huber'],\n",
    "    'alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0],\n",
    "    'max_iter': [1000, 2000, 3000, 4000, 5000],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "}\n",
    "# Create the BayesSearchCV object with the SGDClassifier and parameter distribution\n",
    "bayes_search = BayesSearchCV(model_sgd, param_space, cv=3, scoring=scorer_mcc, \n",
    "                             n_jobs=-1, n_iter=30, random_state=seed)\n",
    "\n",
    "# Perform the Bayesian optimization by fitting training data\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and corresponding MCC score found by the Bayesian search\n",
    "print(\"Best parameters: \", bayes_search.best_params_)\n",
    "print(\"Best score: \", bayes_search.best_score_)\n",
    "\n",
    "# Evaluate the model with chosen parameters on the test set\n",
    "best_estimator = bayes_search.best_estimator_\n",
    "valid_mcc = best_estimator.score(X_val, y_val)\n",
    "print(\"Valid MCC: \", valid_mcc)\n",
    "\n",
    "# Time to run: 36 minutes in a 48 core CPU\n",
    "# Best parameters:  OrderedDict([('alpha', 0.0001), ('loss', 'modified_huber'), ('max_iter', 2000), ('penalty', 'elasticnet')])\n",
    "# Best score:  0.9068535026549907\n",
    "# Valid MCC:  0.963302752293578"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
